{"componentChunkName":"component---node-modules-lekoarts-gatsby-theme-minimal-blog-core-src-templates-post-query-tsx","path":"/up-and-running-with-kafka-on-aws-eks-using-strimzi","result":{"data":{"post":{"__typename":"MdxPost","slug":"/up-and-running-with-kafka-on-aws-eks-using-strimzi","title":"Up And Running With Kafka On AWS EKS Using Strimzi","date":"09.10.2019","tags":[{"name":"kubernetes","slug":"kubernetes"},{"name":"aws","slug":"aws"}],"description":null,"canonicalUrl":null,"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Up And Running With Kafka On AWS EKS Using Strimzi\",\n  \"date\": \"2019-10-09T03:30:32.000Z\",\n  \"tags\": [\"kubernetes\", \"aws\"]\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h3\", null, \"Contents\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"a\", {\n    href: \"#configure-the-aws-cli\"\n  }, \"Configure the AWS CLI\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"a\", {\n    href: \"#create-the-eks-cluster\"\n  }, \"Create the EKS cluster\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"a\", {\n    href: \"#enter-k8s\"\n  }, \"Enter Kubernetes\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"a\", {\n    href: \"#install-and-configure-helm\"\n  }, \"Install and configure Helm\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"a\", {\n    href: \"#install-strimzi-kafka-operator\"\n  }, \"Install the Strimzi Kafka Operator\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"a\", {\n    href: \"#deploy-kaka-cluster\"\n  }, \"Deploying the Kafka cluster\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"a\", {\n    href: \"#analysis\"\n  }, \"Analysis\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"a\", {\n    href: \"#test-kafka-cluster\"\n  }, \"Test the Kafka cluster with Node.js clients\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"a\", {\n    href: \"#clean-up\"\n  }, \"Clean up!\"))), mdx(\"p\", null, \"Let's get right into it, then!\"), mdx(\"p\", null, \"We will be using \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://eksctl.io/\"\n  }, mdx(\"inlineCode\", {\n    parentName: \"a\"\n  }, \"eksctl\")), \", the official CLI for Amazon EKS, to spin up our K8s cluster.\"), mdx(\"h3\", null, \"Configure the AWS CLI \", mdx(\"a\", {\n    name: \"configure-the-aws-cli\"\n  })), mdx(\"p\", null, \"Ensure that the AWS CLI is \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html\"\n  }, \"configured\"), \". To view your configuration:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-go\"\n  }, \"$ aws configure list\\n      Name                    Value             Type    Location\\n      ----                    -----             ----    --------\\n   profile                <not set>             None    None\\naccess_key     ****************7ONG shared-credentials-file    \\nsecret_key     ****************lbQg shared-credentials-file    \\n    region               ap-south-1      config-file    ~/.aws/config\\n\")), mdx(\"p\", null, \"Note: The aws CLI config and credentials details are usually stored at \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"~/.aws/config\"), \" and \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"~/.aws/credentials\"), \" respectively.\"), mdx(\"h3\", null, \"Create the EKS cluster \", mdx(\"a\", {\n    name: \"create-the-eks-cluster\"\n  })), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"\\n$ eksctl create cluster --name=kafka-eks-cluster --nodes=4 --region=ap-south-1\\n\\n[\\u2139]  using region ap-south-1\\n[\\u2139]  setting availability zones to [ap-south-1b ap-south-1a ap-south-1c]\\n[\\u2139]  subnets for ap-south-1b - public:192.168.0.0/19 private:192.168.96.0/19\\n[\\u2139]  subnets for ap-south-1a - public:192.168.32.0/19 private:192.168.128.0/19\\n[\\u2139]  subnets for ap-south-1c - public:192.168.64.0/19 private:192.168.160.0/19\\n[\\u2139]  nodegroup \\\"ng-9f3cbfc7\\\" will use \\\"ami-09c3eb35bb3be46a4\\\" [AmazonLinux2/1.12]\\n[\\u2139]  creating EKS cluster \\\"kafka-eks-cluster\\\" in \\\"ap-south-1\\\" region\\n[\\u2139]  will create 2 separate CloudFormation stacks for cluster itself and the initial nodegroup\\n[\\u2139]  if you encounter any issues, check CloudFormation console or try 'eksctl utils describe-stacks --region=ap-south-1 --name=kafka-eks-cluster'\\n[\\u2139]  2 sequential tasks: { create cluster control plane \\\"kafka-eks-cluster\\\", create nodegroup \\\"ng-9f3cbfc7\\\" }\\n[\\u2139]  building cluster stack \\\"eksctl-kafka-eks-cluster-cluster\\\"\\n[\\u2139]  deploying stack \\\"eksctl-kafka-eks-cluster-cluster\\\"\\n[\\u2139]  building nodegroup stack \\\"eksctl-kafka-eks-cluster-nodegroup-ng-9f3cbfc7\\\"\\n[\\u2139]  --nodes-min=4 was set automatically for nodegroup ng-9f3cbfc7\\n[\\u2139]  --nodes-max=4 was set automatically for nodegroup ng-9f3cbfc7\\n[\\u2139]  deploying stack \\\"eksctl-kafka-eks-cluster-nodegroup-ng-9f3cbfc7\\\"\\n[\\u2714]  all EKS cluster resource for \\\"kafka-eks-cluster\\\" had been created\\n[\\u2714]  saved kubeconfig as \\\"/Users/Bensooraj/.kube/config\\\"\\n[\\u2139]  adding role \\\"arn:aws:iam::account_numer:role/eksctl-kafka-eks-cluster-nodegrou-NodeInstanceRole-IG63RKPE03YQ\\\" to auth ConfigMap\\n[\\u2139]  nodegroup \\\"ng-9f3cbfc7\\\" has 0 node(s)\\n[\\u2139]  waiting for at least 4 node(s) to become ready in \\\"ng-9f3cbfc7\\\"\\n[\\u2139]  nodegroup \\\"ng-9f3cbfc7\\\" has 4 node(s)\\n[\\u2139]  node \\\"ip-192-168-25-34.ap-south-1.compute.internal\\\" is ready\\n[\\u2139]  node \\\"ip-192-168-50-249.ap-south-1.compute.internal\\\" is ready\\n[\\u2139]  node \\\"ip-192-168-62-231.ap-south-1.compute.internal\\\" is ready\\n[\\u2139]  node \\\"ip-192-168-69-95.ap-south-1.compute.internal\\\" is ready\\n[\\u2139]  kubectl command should work with \\\"/Users/Bensooraj/.kube/config\\\", try 'kubectl get nodes'\\n[\\u2714]  EKS cluster \\\"kafka-eks-cluster\\\" in \\\"ap-south-1\\\" region is ready\\n\\n\")), mdx(\"p\", null, \"A k8s cluster by the name \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"kafka-eks-cluster\"), \" will be created with 4 nodes (instance type: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://aws.amazon.com/ec2/instance-types/\"\n  }, \"m5.large\"), \") in the Mumbai region (ap-south-1). You can view these in the AWS Console UI as well,\"), mdx(\"p\", null, \"EKS:\\n\", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"960px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"27.083333333333332%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAz0lEQVQY032Qu07EMBRE8/8FBX9Ci8Q3ICRKihWKYCMn8duJH3CwvRtEgbYY+eqOPXPkYVGaSQiWdcWHgPced0PN18Zgnav3N+x0wpxesO+vGDkzmGqO44hUipgSMUZSPW9JaV3DHSFm/PMD9vEO93SP+3hjuDSF3t7msG09dL/qv/ko7irf7AW2DK7mDC0s54yYF6RUff4rVcmFmJmr3+jarp1fpXRSbTSl7kpOhBbYyFrrWXo+pcOGvT+IV5LDv1AdiuSUkW5lUuffb2pwP7uGgYBqRHvYAAAAAElFTkSuQmCC')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"AWS EKS UI\",\n    \"title\": \"AWS EKS UI\",\n    \"src\": \"/static/7be03791a3ba6cd97ef17868d86182af/7d769/1_xamksw0rnxsxjohb8zkh.png\",\n    \"srcSet\": [\"/static/7be03791a3ba6cd97ef17868d86182af/5243c/1_xamksw0rnxsxjohb8zkh.png 240w\", \"/static/7be03791a3ba6cd97ef17868d86182af/ab158/1_xamksw0rnxsxjohb8zkh.png 480w\", \"/static/7be03791a3ba6cd97ef17868d86182af/7d769/1_xamksw0rnxsxjohb8zkh.png 960w\", \"/static/7be03791a3ba6cd97ef17868d86182af/87339/1_xamksw0rnxsxjohb8zkh.png 1440w\", \"/static/7be03791a3ba6cd97ef17868d86182af/88b03/1_xamksw0rnxsxjohb8zkh.png 1920w\", \"/static/7be03791a3ba6cd97ef17868d86182af/69d2d/1_xamksw0rnxsxjohb8zkh.png 1928w\"],\n    \"sizes\": \"(max-width: 960px) 100vw, 960px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n    \")), mdx(\"p\", null, \"CloudFormation UI:\\n\", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"960px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"27.500000000000004%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAABYlAAAWJQFJUiTwAAABAklEQVQY022QSW6DQBBF+/4HSK7jg0TKxoAw0PMENPr+1VYSL4L01JSq9GpQ39OKzVgYaxFTQogR8R98CJ2ef6/jfwwOfvzqqOF+R60V+3Fg33fy8/5xMOe8pyShsFZkuRQYH6F9QtomxNsn0u0DqlKQmJSCXynf43wTS0zO1l5y51FY71KFtg6GG5YG5BNQid0c120sbJScfGXiwO7n0ToizTlDa9NF13V1sZepQ3zFe+2okHcMOmINFQsxiWJOMrsJi58Zb5BPmmwUWpmIA0gDuemybrDO9anlpsrG0oWTiRiJSwWVnSYzYtQDHm7uK8vxRSg81pU3DR0RCuumobn6E2ZFzXUS9NEHAAAAAElFTkSuQmCC')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Cloudformation UI\",\n    \"title\": \"Cloudformation UI\",\n    \"src\": \"/static/674ebbbe893db534ce4e9f0f654fb3d5/7d769/2_8gj6kw97f6bxkm6u9a44.png\",\n    \"srcSet\": [\"/static/674ebbbe893db534ce4e9f0f654fb3d5/5243c/2_8gj6kw97f6bxkm6u9a44.png 240w\", \"/static/674ebbbe893db534ce4e9f0f654fb3d5/ab158/2_8gj6kw97f6bxkm6u9a44.png 480w\", \"/static/674ebbbe893db534ce4e9f0f654fb3d5/7d769/2_8gj6kw97f6bxkm6u9a44.png 960w\", \"/static/674ebbbe893db534ce4e9f0f654fb3d5/87339/2_8gj6kw97f6bxkm6u9a44.png 1440w\", \"/static/674ebbbe893db534ce4e9f0f654fb3d5/88b03/2_8gj6kw97f6bxkm6u9a44.png 1920w\", \"/static/674ebbbe893db534ce4e9f0f654fb3d5/d1a1d/2_8gj6kw97f6bxkm6u9a44.png 2362w\"],\n    \"sizes\": \"(max-width: 960px) 100vw, 960px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n    \")), mdx(\"p\", null, \"Also, after the cluster is created, the appropriate kubernetes configuration will be added to your kubeconfig file (defaults to \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"~/.kube/config\"), \"). The path to the kubeconfig file can be overridden using the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"--kubeconfig\"), \" flag.\"), mdx(\"h3\", null, \"Enter Kubernetes \", mdx(\"a\", {\n    name: \"enter-k8s\"\n  })), mdx(\"p\", null, \"Fetching all k8s controllers lists the default \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"kubernetes\"), \" service. This confirms that \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"kubectl\"), \" is properly configured to point to the cluster that we just created.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\"\n  }, \"$ kubectl get all\\nNAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE\\nservice/kubernetes   ClusterIP   10.100.0.1   <none>        443/TCP   19m\\n\")), mdx(\"h4\", null, \"Install and configure Helm \", mdx(\"a\", {\n    name: \"install-and-configure-helm\"\n  })), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://helm.sh\"\n  }, \"Helm\"), \" is a package manager and application management tool for Kubernetes that packages multiple Kubernetes resources into a single logical deployment unit called Chart.\")), mdx(\"p\", null, \"I use \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Homebrew\"), \", so the installation was pretty straightforward: \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"brew install kubernetes-helm\"), \".\"), mdx(\"p\", null, \"Alternatively, to install \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"helm\"), \", run the following:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\"\n  }, \"$ cd ~/eks-kafka-strimzi\\n\\n$ curl https://raw.githubusercontent.com/kubernetes/helm/master/scripts/get > get_helm.sh\\n\\n$ chmod +x get_helm.sh\\n\\n$ ./get_helm.sh\\n\")), mdx(\"p\", null, \"Read through their \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://helm.sh/docs/using_helm/#installing-helm\"\n  }, \"installation guide\"), \", if you are looking for more options.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Do not run \", mdx(\"inlineCode\", {\n    parentName: \"strong\"\n  }, \"helm init\"), \" yet.\")), mdx(\"p\", null, mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Helm\"), \" relies on a service called \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, mdx(\"inlineCode\", {\n    parentName: \"strong\"\n  }, \"tiller\")), \" that requires special permission on the kubernetes cluster, so we need to build a \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, mdx(\"inlineCode\", {\n    parentName: \"strong\"\n  }, \"Service Account\")), \" (RBAC access) for \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, mdx(\"inlineCode\", {\n    parentName: \"strong\"\n  }, \"tiller\")), \" to use.\"), mdx(\"p\", null, \"The \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"rbac.yaml\"), \" file would look like the following:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-yaml\"\n  }, \"---\\napiVersion: v1\\nkind: ServiceAccount\\nmetadata:\\n  name: tiller\\n  namespace: kube-system\\n---\\napiVersion: rbac.authorization.k8s.io/v1beta1\\nkind: ClusterRoleBinding\\nmetadata:\\n  name: tiller\\nroleRef:\\n  apiGroup: rbac.authorization.k8s.io\\n  kind: ClusterRole\\n  name: cluster-admin\\nsubjects:\\n  - kind: ServiceAccount\\n    name: tiller\\n    namespace: kube-system\\n\")), mdx(\"p\", null, \"Apply this to the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"kafka-eks-cluster\"), \" cluster:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\"\n  }, \"$ kubectl apply -f rbac.yaml\\nserviceaccount/tiller created\\nclusterrolebinding.rbac.authorization.k8s.io/tiller created\\n\\n# Verify (listing only the relevant ones)\\n$ kubectl get sa,clusterrolebindings --namespace=kube-system\\nNAME                        SECRETS   AGE\\n.\\nserviceaccount/tiller       1         5m22s\\n.\\n\\nNAME                                                                                                AGE\\n.\\nclusterrolebinding.rbac.authorization.k8s.io/tiller                                                 5m23s\\n.\\n\")), mdx(\"p\", null, \"Now, run \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, mdx(\"inlineCode\", {\n    parentName: \"strong\"\n  }, \"helm init\")), \" using the service account we setup. This will install tiller into the cluster which gives it access to manage resources in your cluster.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\"\n  }, \"$ helm init --service-account=tiller\\n\\n$HELM_HOME has been configured at /Users/Bensooraj/.helm.\\n\\nTiller (the Helm server-side component) has been installed into your Kubernetes Cluster.\\n\\nPlease note: by default, Tiller is deployed with an insecure 'allow unauthenticated users' policy.\\n\\nTo prevent this, run `helm init` with the --tiller-tls-verify flag.\\n\\nFor more information on securing your installation see: https://docs.helm.sh/using_helm/#securing-your-helm-installation\\n\")), mdx(\"h3\", null, \"Install the Strimzi Kafka Operator \", mdx(\"a\", {\n    name: \"install-strimzi-kafka-operator\"\n  })), mdx(\"p\", null, \"Add the Strimzi repository and install the Strimzi Helm Chart:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\"\n  }, \"# Add the repo\\n$ helm repo add strimzi http://strimzi.io/charts/\\n\\\"strimzi\\\" has been added to your repositories\\n\\n# Search for all Strimzi  charts\\n$ helm search strim\\nNAME                            CHART VERSION   APP VERSION DESCRIPTION                \\nstrimzi/strimzi-kafka-operator  0.14.0          0.14.0      Strimzi: Kafka as a Service\\n\\n# Install the kafka operator\\n$ helm install strimzi/strimzi-kafka-operator\\nNAME:   bulging-gnat\\nLAST DEPLOYED: Wed Oct  2 15:23:45 2019\\nNAMESPACE: default\\nSTATUS: DEPLOYED\\n\\nRESOURCES:\\n==> v1/ClusterRole\\nNAME                                 AGE\\nstrimzi-cluster-operator-global      0s\\nstrimzi-cluster-operator-namespaced  0s\\nstrimzi-entity-operator              0s\\nstrimzi-kafka-broker                 0s\\nstrimzi-topic-operator               0s\\n\\n==> v1/ClusterRoleBinding\\nNAME                                              AGE\\nstrimzi-cluster-operator                          0s\\nstrimzi-cluster-operator-kafka-broker-delegation  0s\\n\\n==> v1/Deployment\\nNAME                      READY  UP-TO-DATE  AVAILABLE  AGE\\nstrimzi-cluster-operator  0/1    1           0          0s\\n\\n==> v1/Pod(related)\\nNAME                                       READY  STATUS             RESTARTS  AGE\\nstrimzi-cluster-operator-6667fbc5f8-cqvdv  0/1    ContainerCreating  0         0s\\n\\n==> v1/RoleBinding\\nNAME                                                 AGE\\nstrimzi-cluster-operator                             0s\\nstrimzi-cluster-operator-entity-operator-delegation  0s\\nstrimzi-cluster-operator-topic-operator-delegation   0s\\n\\n==> v1/ServiceAccount\\nNAME                      SECRETS  AGE\\nstrimzi-cluster-operator  1        0s\\n\\n==> v1beta1/CustomResourceDefinition\\nNAME                                AGE\\nkafkabridges.kafka.strimzi.io       0s\\nkafkaconnects.kafka.strimzi.io      0s\\nkafkaconnects2is.kafka.strimzi.io   0s\\nkafkamirrormakers.kafka.strimzi.io  0s\\nkafkas.kafka.strimzi.io             1s\\nkafkatopics.kafka.strimzi.io        1s\\nkafkausers.kafka.strimzi.io         1s\\n\\nNOTES:\\nThank you for installing strimzi-kafka-operator-0.14.0\\n\\nTo create a Kafka cluster refer to the following documentation.\\n\\nhttps://strimzi.io/docs/0.14.0/#kafka-cluster-str\\n\")), mdx(\"p\", null, \"List all the kubernetes objects created again:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\"\n  }, \"$ kubectl get all\\nNAME                                            READY   STATUS    RESTARTS   AGE\\npod/strimzi-cluster-operator-6667fbc5f8-cqvdv   1/1     Running   0          9m25s\\n\\nNAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE\\nservice/kubernetes   ClusterIP   10.100.0.1   <none>        443/TCP   90m\\n\\nNAME                                       DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE\\ndeployment.apps/strimzi-cluster-operator   1         1         1            1           9m25s\\n\\nNAME                                                  DESIRED   CURRENT   READY   AGE\\nreplicaset.apps/strimzi-cluster-operator-6667fbc5f8   1         1         1       9m26s\\n\")), mdx(\"h3\", null, \"Deploying the Kafka cluster \", mdx(\"a\", {\n    name: \"deploy-kaka-cluster\"\n  })), mdx(\"p\", null, \"We will now create a Kafka cluster with 3 brokers. The YAML file (\", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"kafka-cluster.Kafka.yaml\"), \") for creating the Kafka cluster would like the following:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-yaml\"\n  }, \"apiVersion: kafka.strimzi.io/v1beta1\\nkind: Kafka\\nmetadata:\\n  name: kafka-cluster\\nspec:\\n  kafka:\\n    version: 2.3.0 # Kafka version\\n    replicas: 3 # Replicas specifies the number of broker nodes.\\n    listeners: # Listeners configure how clients connect to the Kafka cluster\\n      plain: {} # 9092\\n      tls: {} # 9093\\n    config:\\n      offsets.topic.replication.factor: 3\\n      transaction.state.log.replication.factor: 3\\n      transaction.state.log.min.isr: 2\\n      log.message.format.version: \\\"2.3\\\"\\n      delete.topic.enable: \\\"true\\\"\\n    storage:\\n      type: persistent-claim\\n      size: 10Gi\\n      deleteClaim: false\\n  zookeeper:\\n    replicas: 3\\n    storage:\\n      type: persistent-claim # Persistent storage backed by AWS EBS\\n      size: 10Gi\\n      deleteClaim: false\\n  entityOperator:\\n    topicOperator: {} # Operator for topic administration\\n    userOperator: {}\\n\\n\")), mdx(\"p\", null, \"Apply the above YAML file:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\"\n  }, \"$ kubectl apply -f kafka-cluster.Kafka.yaml\\n\")), mdx(\"h3\", null, \"Analysis \", mdx(\"a\", {\n    name: \"analysis\"\n  })), mdx(\"p\", null, \"This is where things get interesting. We will now analyse \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"some\"), \" of the k8s resources which the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"strimzi kafka operator\"), \" has created for us under the hood.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\"\n  }, \"$ kubectl get statefulsets.apps,pod,deployments,svc\\nNAME                                       DESIRED   CURRENT   AGE\\nstatefulset.apps/kafka-cluster-kafka       3         3         78m\\nstatefulset.apps/kafka-cluster-zookeeper   3         3         79m\\n\\nNAME                                                 READY   STATUS    RESTARTS   AGE\\npod/kafka-cluster-entity-operator-54cb77fd9d-9zbcx   3/3     Running   0          77m\\npod/kafka-cluster-kafka-0                            2/2     Running   0          78m\\npod/kafka-cluster-kafka-1                            2/2     Running   0          78m\\npod/kafka-cluster-kafka-2                            2/2     Running   0          78m\\npod/kafka-cluster-zookeeper-0                        2/2     Running   0          79m\\npod/kafka-cluster-zookeeper-1                        2/2     Running   0          79m\\npod/kafka-cluster-zookeeper-2                        2/2     Running   0          79m\\npod/strimzi-cluster-operator-6667fbc5f8-cqvdv        1/1     Running   0          172m\\n\\nNAME                                                  DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE\\ndeployment.extensions/kafka-cluster-entity-operator   1         1         1            1           77m\\ndeployment.extensions/strimzi-cluster-operator        1         1         1            1           172m\\n\\nNAME                                     TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                      AGE\\nservice/kafka-cluster-kafka-bootstrap    ClusterIP   10.100.177.177   <none>        9091/TCP,9092/TCP,9093/TCP   78m\\nservice/kafka-cluster-kafka-brokers      ClusterIP   None             <none>        9091/TCP,9092/TCP,9093/TCP   78m\\nservice/kafka-cluster-zookeeper-client   ClusterIP   10.100.199.128   <none>        2181/TCP                     79m\\nservice/kafka-cluster-zookeeper-nodes    ClusterIP   None             <none>        2181/TCP,2888/TCP,3888/TCP   79m\\nservice/kubernetes                       ClusterIP   10.100.0.1       <none>        443/TCP                      4h13m\\n\")), mdx(\"p\", null, \"Points to note:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"The StatefulSet \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"kafka-cluster-zookeeper\"), \" has created 3 pods - \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"kafka-cluster-zookeeper-0\"), \", \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"kafka-cluster-zookeeper-1\"), \" and \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"kafka-cluster-zookeeper-2\"), \". The headless service \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"kafka-cluster-zookeeper-nodes\"), \" facilitates network identity of these 3 pods (the 3 Zookeeper nodes).\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"The StatefulSet \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"kafka-cluster-kafka\"), \" has created 3 pods - \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"kafka-cluster-kafka-0\"), \", \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"kafka-cluster-kafka-1\"), \" and \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"kafka-cluster-kafka-2\"), \". The headless service \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"kafka-cluster-kafka-brokers\"), \" facilitates network identity of these 3 pods (the 3 Kafka brokers).\")), mdx(\"p\", null, \"Persistent volumes are dynamically provisioned:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\"\n  }, \"$ kubectl get pv,pvc\\nNAME                                                        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                                    STORAGECLASS   REASON   AGE\\npersistentvolume/pvc-7ff2909f-e507-11e9-91df-0a1e73fdd786   10Gi       RWO            Delete           Bound    default/data-kafka-cluster-zookeeper-1   gp2                     11h\\npersistentvolume/pvc-7ff290c4-e507-11e9-91df-0a1e73fdd786   10Gi       RWO            Delete           Bound    default/data-kafka-cluster-zookeeper-2   gp2                     11h\\npersistentvolume/pvc-7ffd1d22-e507-11e9-a775-029ce0835b96   10Gi       RWO            Delete           Bound    default/data-kafka-cluster-zookeeper-0   gp2                     11h\\npersistentvolume/pvc-a5997b77-e507-11e9-91df-0a1e73fdd786   10Gi       RWO            Delete           Bound    default/data-kafka-cluster-kafka-0       gp2                     11h\\npersistentvolume/pvc-a599e52b-e507-11e9-91df-0a1e73fdd786   10Gi       RWO            Delete           Bound    default/data-kafka-cluster-kafka-1       gp2                     11h\\npersistentvolume/pvc-a59c6cd2-e507-11e9-91df-0a1e73fdd786   10Gi       RWO            Delete           Bound    default/data-kafka-cluster-kafka-2       gp2                     11h\\n\\nNAME                                                   STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE\\npersistentvolumeclaim/data-kafka-cluster-kafka-0       Bound    pvc-a5997b77-e507-11e9-91df-0a1e73fdd786   10Gi       RWO            gp2            11h\\npersistentvolumeclaim/data-kafka-cluster-kafka-1       Bound    pvc-a599e52b-e507-11e9-91df-0a1e73fdd786   10Gi       RWO            gp2            11h\\npersistentvolumeclaim/data-kafka-cluster-kafka-2       Bound    pvc-a59c6cd2-e507-11e9-91df-0a1e73fdd786   10Gi       RWO            gp2            11h\\npersistentvolumeclaim/data-kafka-cluster-zookeeper-0   Bound    pvc-7ffd1d22-e507-11e9-a775-029ce0835b96   10Gi       RWO            gp2            11h\\npersistentvolumeclaim/data-kafka-cluster-zookeeper-1   Bound    pvc-7ff2909f-e507-11e9-91df-0a1e73fdd786   10Gi       RWO            gp2            11h\\npersistentvolumeclaim/data-kafka-cluster-zookeeper-2   Bound    pvc-7ff290c4-e507-11e9-91df-0a1e73fdd786   10Gi       RWO            gp2            11h\\n\")), mdx(\"p\", null, \"You can view the provisioned AWS EBS volumes in the UI as well:\\n\", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"960px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"32.49999999999999%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAABYlAAAWJQFJUiTwAAABAklEQVQoz52Qa26DQAyE9+g9UH/0Gj0DiAqWx0IgUQKId6b5LBH1d1ca2WuPx7PrPr5SfX5XuoRS/TDqP2eaJg3DoHme5H58UBEuquta1+tVt9tNXdep73sDxMfj8cZ5p9e2rUIIyrJMURSpqio5n6Vq6qCmaUwUQhzHyvPcQD1NUwOD9KmTJ0liIqAoCjPkEMkybwXvvcZxNAJNwHNwxMHduq6WE+GdCwCuHUW2UyBSJOfZYFlm3e93E6G3bZvly7Io97nKsnzxvTmG5xhiC04RMocv0vmf8zyb0PF8vh0+XzmC5xyRGbiOP2ILz2L7vu82RP73fhyH5cQTiJ5cjPBlv0l1FBRuj3wZAAAAAElFTkSuQmCC')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"EBS UI\",\n    \"title\": \"EBS UI\",\n    \"src\": \"/static/06b6af4535990e37d0cb899301f7e028/7d769/3_zys2wmubcb42glzzp23m.png\",\n    \"srcSet\": [\"/static/06b6af4535990e37d0cb899301f7e028/5243c/3_zys2wmubcb42glzzp23m.png 240w\", \"/static/06b6af4535990e37d0cb899301f7e028/ab158/3_zys2wmubcb42glzzp23m.png 480w\", \"/static/06b6af4535990e37d0cb899301f7e028/7d769/3_zys2wmubcb42glzzp23m.png 960w\", \"/static/06b6af4535990e37d0cb899301f7e028/87339/3_zys2wmubcb42glzzp23m.png 1440w\", \"/static/06b6af4535990e37d0cb899301f7e028/88b03/3_zys2wmubcb42glzzp23m.png 1920w\", \"/static/06b6af4535990e37d0cb899301f7e028/62b30/3_zys2wmubcb42glzzp23m.png 2136w\"],\n    \"sizes\": \"(max-width: 960px) 100vw, 960px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n    \")), mdx(\"h3\", null, \"Create topics\"), mdx(\"p\", null, \"Before we get started with clients we need to create a \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"topic\"), \" (with 3 partitions and a replication factor of 3), over which our \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"producer\"), \" and the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"consumer\"), \" and produce messages and consume messages on respectively.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-yaml\"\n  }, \"apiVersion: kafka.strimzi.io/v1beta1\\nkind: KafkaTopic\\nmetadata:\\n  name: test-topic\\n  labels:\\n    strimzi.io/cluster: kafka-cluster\\nspec:\\n  partitions: 3\\n  replicas: 3\\n\")), mdx(\"p\", null, \"Apply the YAML to the k8s cluster:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\"\n  }, \"$ kubectl apply -f create-topics.yaml\\nkafkatopic.kafka.strimzi.io/test-topic created\\n\")), mdx(\"h3\", null, \"Test the Kafka cluster with Node.js clients \", mdx(\"a\", {\n    name: \"test-kafka-cluster\"\n  })), mdx(\"p\", null, \"The multi-broker Kafka cluster that we deployed is backed by \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"statefulset\"), \"s and their corresponding headless \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"service\"), \"s.\"), mdx(\"p\", null, \"Since each Pod (Kafka broker) now has a network identity, clients can connect to the Kafka brokers via a combination of the pod name and service name: \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"$(podname).$(governing service domain)\"), \". In our case, these would be the following URLs:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"kafka-cluster-kafka-0.kafka-cluster-kafka-brokers\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"kafka-cluster-kafka-1.kafka-cluster-kafka-brokers\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"kafka-cluster-kafka-2.kafka-cluster-kafka-brokers\"))), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Note\"), \":\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"If the Kafka cluster is deployed in a different namespace, you will have to expand it a little further: \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"$(podname).$(service name).$(namespace).svc.cluster.local\"), \".\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Alternatively, the clients can connect to the Kafka cluster using the Service \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"kafka-cluster-kafka-bootstrap:9092\"), \" as well. It distributes the connection over the three broker specific endpoints I have listed above. As I no longer keep track of the individual broker endpoints, this method plays out well when I have to scale up or down the number of brokers in the Kafka cluster.\")), mdx(\"p\", null, \"First, clone this repo: {% github bensooraj/strimzi-kafka-aws-eks no-readme %}\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\"\n  }, \"# Create the configmap, which contains details such as the broker DNS names, topic name and consumer group ID\\n$ kubectl apply -f test/k8s/config.yaml\\nconfigmap/kafka-client-config created\\n\\n# Create the producer deployment\\n$ kubectl apply -f test/k8s/producer.Deployment.yaml\\ndeployment.apps/node-test-producer created\\n\\n# Expose the producer deployment via a service of type LoadBalancer (backed by the AWS Elastic Load Balancer). This just makes it easy for me to curl from postman\\n$ kubectl apply -f test/k8s/producer.Service.yaml\\nservice/node-test-producer created\\n\\n# Finally, create the consumer deployment\\n$ kubectl apply -f test/k8s/consumer.Deployment.yaml\\ndeployment.apps/node-test-consumer created\\n\\n\")), mdx(\"p\", null, \"If you list the producer service that we created, you would notice a \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"URL\"), \" under EXTERNAL-IP:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\"\n  }, \"$ kubectl get svc\\nNAME                             TYPE           CLUSTER-IP       EXTERNAL-IP                                                                PORT(S)                      AGE\\n.\\n.\\nnode-test-producer               LoadBalancer   10.100.145.203   ac5f3d0d1e55a11e9a775029ce0835b9-2040242746.ap-south-1.elb.amazonaws.com   80:31231/TCP                 55m\\n\\n\")), mdx(\"p\", null, \"The URL \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"ac5f3d0d1e55a11e9a775029ce0835b9-2040242746.ap-south-1.elb.amazonaws.com\"), \" is an \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"AWS ELB\"), \" backed public endpoint which we will be querying for producing messages to the Kafka cluster.\"), mdx(\"p\", null, \"Also, you can see that there is 1 producer and 3 consumers (one for each partition of the topic \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"test-topic\"), \"):\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\"\n  }, \"$ kubectl get pod\\nNAME                                             READY   STATUS    RESTARTS   AGE\\nnode-test-consumer-96b44cbcb-gs2km               1/1     Running   0          125m\\nnode-test-consumer-96b44cbcb-ptvjd               1/1     Running   0          125m\\nnode-test-consumer-96b44cbcb-xk75j               1/1     Running   0          125m\\nnode-test-producer-846d9c5986-vcsf2              1/1     Running   0          125m\\n\")), mdx(\"p\", null, \"The producer app basically exposes 3 URLs:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"/kafka-test/green/:message\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"/kafka-test/blue/:message\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"/kafka-test/cyan/:message\"))), mdx(\"p\", null, \"Where \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \":message\"), \" can be any valid string. Each of these URLs produce a \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"message\"), \" along with the \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"colour\"), \" information to the topic \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"test-topic\"), \".\"), mdx(\"p\", null, \"The consumer group (the 3 consumer pods that we spin-up) listening for any incoming messages from the topic \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"test-topic\"), \", then receives these messages and prints them on to the console according to the colour instruction.\"), mdx(\"p\", null, \"I \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"curl\"), \" each URL 3 times. From the following GIF you can see how message consumption is distributed across the 3 consumers in a \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"round-robin\"), \" manner:\"), mdx(\"p\", null, mdx(\"img\", {\n    parentName: \"p\",\n    \"src\": \"./posts/0/4_a3b19iryt7pxff3z8ust.gif\",\n    \"alt\": \"Producer and Consumer Visualisation\"\n  })), mdx(\"h3\", null, \"Clean Up! \", mdx(\"a\", {\n    name: \"clean-up\"\n  })), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\"\n  }, \"\\n# Delete the test producer and consumer apps:\\n$ kubectl delete -f test/k8s/\\nconfigmap \\\"kafka-client-config\\\" deleted\\ndeployment.apps \\\"node-test-consumer\\\" deleted\\ndeployment.apps \\\"node-test-producer\\\" deleted\\nservice \\\"node-test-producer\\\" deleted\\n\\n# Delete the Kafka cluster\\n$ kubectl delete kafka kafka-cluster\\nkafka.kafka.strimzi.io \\\"kafka-cluster\\\" deleted\\n\\n# Delete the Strimzi cluster operator\\n$ kubectl delete deployments. strimzi-cluster-operator\\ndeployment.extensions \\\"strimzi-cluster-operator\\\" deleted\\n\\n# Manually delete the persistent volumes\\n# Kafka\\n$ kubectl delete pvc data-kafka-cluster-kafka-0\\n$ kubectl delete pvc data-kafka-cluster-kafka-1\\n$ kubectl delete pvc data-kafka-cluster-kafka-2\\n# Zookeeper\\n$ kubectl delete pvc data-kafka-cluster-zookeeper-0\\n$ kubectl delete pvc data-kafka-cluster-zookeeper-1\\n$ kubectl delete pvc data-kafka-cluster-zookeeper-2\\n\")), mdx(\"p\", null, \"Finally, delete the EKS cluster:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\"\n  }, \"$ eksctl delete cluster kafka-eks-cluster\\n[\\u2139]  using region ap-south-1\\n[\\u2139]  deleting EKS cluster \\\"kafka-eks-cluster\\\"\\n[\\u2714]  kubeconfig has been updated\\n[\\u2139]  2 sequential tasks: { delete nodegroup \\\"ng-9f3cbfc7\\\", delete cluster control plane \\\"kafka-eks-cluster\\\" [async] }\\n[\\u2139]  will delete stack \\\"eksctl-kafka-eks-cluster-nodegroup-ng-9f3cbfc7\\\"\\n[\\u2139]  waiting for stack \\\"eksctl-kafka-eks-cluster-nodegroup-ng-9f3cbfc7\\\" to get deleted\\n[\\u2139]  will delete stack \\\"eksctl-kafka-eks-cluster-cluster\\\"\\n[\\u2714]  all cluster resources were deleted\\n\")), mdx(\"p\", null, \"Hope this helped!\"), mdx(\"hr\", null), mdx(\"p\", null, \"Note: \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"This is not a tutorial per se, instead, this is me recording my observations as I setup a Kafka cluster for the first time on a Kubernetes platform using Strimzi.\")));\n}\n;\nMDXContent.isMDXComponent = true;","excerpt":"Contents Let's get right into it, then! We will be using  eksctl , the official CLI for Amazon EKS, to spin up our K8s cluster. Configure…","timeToRead":3,"banner":null}},"pageContext":{"slug":"/up-and-running-with-kafka-on-aws-eks-using-strimzi","formatString":"DD.MM.YYYY"}},"staticQueryHashes":["3090400250","3090400250","318001574"]}