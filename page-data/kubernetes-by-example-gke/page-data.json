{"componentChunkName":"component---node-modules-lekoarts-gatsby-theme-minimal-blog-core-src-templates-post-query-tsx","path":"/kubernetes-by-example-gke","result":{"data":{"post":{"__typename":"MdxPost","slug":"/kubernetes-by-example-gke","title":"Kubernetes By Example (GKE)","date":"27.03.2019","tags":[{"name":"kubernetes","slug":"kubernetes"}],"description":null,"canonicalUrl":null,"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Kubernetes By Example (GKE)\",\n  \"date\": \"2019-03-27T02:40:21.000Z\",\n  \"tags\": [\"kubernetes\"]\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, mdx(\"em\", {\n    parentName: \"p\"\n  }, mdx(\"strong\", {\n    parentName: \"em\"\n  }, \"Note\"), \": This is a journal of my learnings as I walk through the entire \", mdx(\"a\", {\n    parentName: \"em\",\n    \"href\": \"http://kubernetesbyexample.com\"\n  }, \"Kubernetes By Example\"), \" exercises on \", mdx(\"inlineCode\", {\n    parentName: \"em\"\n  }, \"Google Kubernetes Engine\"), \". I had writted this originally on \", mdx(\"a\", {\n    parentName: \"em\",\n    \"href\": \"https://github.com/bensooraj/bens-k8s-journal/tree/master/Basics/04-Kubernetes-By-Example\"\n  }, \"Github\"), \".\")), mdx(\"h3\", null, \"Contents \", mdx(\"a\", {\n    id: \"top-contents\"\n  })), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#check-config-details\"\n  }, \"Check config details\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#spin-up-a-k8s-cluster-gke\"\n  }, \"Spin-up a k8s cluster (GKE)\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#pods\"\n  }, \"Pods\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#labels\"\n  }, \"Labels\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#deployments\"\n  }, \"Deployments\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#services\"\n  }, \"Services\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#service-discovery\"\n  }, \"Service Discovery\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#port-forward\"\n  }, \"Port Forward\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#health-checks\"\n  }, \"Health Checks\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#environment-variables\"\n  }, \"Environment Variables\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#namespaces\"\n  }, \"Namespaces\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#volumes\"\n  }, \"Volumes\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#secrets\"\n  }, \"Secrets\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#logging\"\n  }, \"Logging\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#jobs\"\n  }, \"Jobs\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#statefulset\"\n  }, \"StatefulSet\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#init-containers\"\n  }, \"Init Containers\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#nodes\"\n  }, \"Nodes\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#api-server-access\"\n  }, \"API Server access\"))), mdx(\"h3\", null, \"Check config details \", mdx(\"a\", {\n    id: \"check-config-details\"\n  })), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2,11,18}\",\n    \"{2,11,18}\": true\n  }, \"# List the active accounts:\\n$ gcloud auth list\\n   Credentialed Accounts\\nACTIVE  ACCOUNT\\n*       xxyyzz@gmail.com\\n\\nTo set the active account, run:\\n    $ gcloud config set account `ACCOUNT`\\n\\n# Checkout the project we are currently in\\n$ gcloud config list project\\n[core]\\nproject = kubernetes-practice-219913\\n\\nYour active configuration is: [default]\\n\\n# List the default/current config values (I wanted the zone and region details):\\n$ gcloud config configurations list\\nNAME     IS_ACTIVE  ACCOUNT               PROJECT                     DEFAULT_ZONE   DEFAULT_REGION\\ndefault  True       xxyyzz@gmail.com  kubernetes-practice-219913  asia-south1-a  asia-south1\\n\")), mdx(\"p\", null, \"[\", mdx(\"sub\", null, mdx(\"sup\", null, mdx(\"a\", {\n    href: \"#top-contents\"\n  }, \"GO TO TOP\"))), \"]\"), mdx(\"h3\", null, \"Spin-up a k8s cluster (GKE) \", mdx(\"a\", {\n    id: \"spin-up-a-k8s-cluster-gke\"\n  })), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2}\",\n    \"{2}\": true\n  }, \"# Create a 3-node cluster and set kubectl context\\n$ gcloud container clusters create k8s-by-example --num-nodes=3\\n\\n# Creating cluster k8s-by-example in asia-south1-a... Cluster is being health-checked (master is healthy)...done.\\n# Created [https://container.googleapis.com/v1/projects/kubernetes-practice-219913/zones/asia-south1-a/clusters/k8s-by-example].\\n# To inspect the contents of your cluster, go to: https://console.cloud.google.com/kubernetes/workload_/gcloud/asia-south1-a/k8s-by-example?project=kubernetes-practice-219913\\n\\nkubeconfig entry generated for k8s-by-example.\\nNAME            LOCATION       MASTER_VERSION  MASTER_IP       MACHINE_TYPE   NODE_VERSION  NUM_NODES  STATUS\\nk8s-by-example  asia-south1-a  1.11.7-gke.4    35.200.190.186  n1-standard-1  1.11.7-gke.4  3          RUNNING\\n\")), mdx(\"p\", null, \"Creating a GKE cluster using \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"gcloud\"), \" automatically makes an entry in the kubconfig file and also set the current context for \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"kubectl\"), \".\"), mdx(\"p\", null, \"[\", mdx(\"sub\", null, mdx(\"sup\", null, mdx(\"a\", {\n    href: \"#top-contents\"\n  }, \"GO TO TOP\"))), \"]\"), mdx(\"h3\", null, \"Pods \", mdx(\"a\", {\n    id: \"pods\"\n  })), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"A pod is a collection of containers sharing a network and mount namespace and is the basic unit of deployment in Kubernetes. All containers in a pod are scheduled on the same node.\")), mdx(\"p\", null, \"A dry-run \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"kubectl run sise --image=mhausenblas/simpleservice:0.5.0 --port=9876 --dry-run=true -o yaml\"), \", gives the following yaml output:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-yaml\"\n  }, \"apiVersion: apps/v1beta1\\nkind: Deployment\\nmetadata:\\n  creationTimestamp: null\\n  labels:\\n    run: sise\\n  name: sise\\nspec:\\n  replicas: 1\\n  selector:\\n    matchLabels:\\n      run: sise\\n  strategy: {}\\n  template:\\n    metadata:\\n      creationTimestamp: null\\n      labels:\\n        run: sise\\n    spec:\\n      containers:\\n        - image: mhausenblas/simpleservice:0.5.0\\n          name: sise\\n          ports:\\n            - containerPort: 9876\\n          resources: {}\\nstatus: {}\\n\")), mdx(\"p\", null, \"Let's run the pod using the image \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"mhausenblas/simpleservice:0.5.0\"), \":\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{1,6,11,16,17,20,24,29}\",\n    \"{1,6,11,16,17,20,24,29}\": true\n  }, \"$ kubectl run sise --image=mhausenblas/simpleservice:0.5.0 --port=9876\\nkubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\\ndeployment.apps/sise created\\n\\n# List out the pod\\n$ kubectl get po -o wide\\nNAME                   READY   STATUS    RESTARTS   AGE   IP          NODE                                            NOMINATED NODE\\nsise-bf8d99689-qgkkk   1/1     Running   0          43s   10.12.1.6   gke-k8s-by-example-default-pool-f7f7edae-09cs   <none>\\n\\n# Grab the IP address\\n$ kubectl describe pods sise-bf8d99689-qgkkk | grep IP\\nIP:                 10.12.1.6\\n\\n# Get inside the pod and access the API using the IP address.\\n# This is accessible from the cluster as well\\n$ kubectl exec -it sise-bf8d99689-qgkkk sh\\n> curl localhost:9876/info\\n{\\\"host\\\": \\\"localhost:9876\\\", \\\"version\\\": \\\"0.5.0\\\", \\\"from\\\": \\\"127.0.0.1\\\"}#\\n\\n> curl 10.12.1.6:9876/info\\n{\\\"host\\\": \\\"10.12.1.6:9876\\\", \\\"version\\\": \\\"0.5.0\\\", \\\"from\\\": \\\"10.12.1.6\\\"}#\\n\\n# List the deployments\\n$ kubectl get deployments.\\nNAME   DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE\\nsise   1         1         1            1           20m\\n\\n# And delete it\\n$ kubectl delete deployments sise\\ndeployment.extensions \\\"sise\\\" deleted\\n\")), mdx(\"h5\", null, \"Using a configuration file\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2,6,11,12,15,19}\",\n    \"{2,6,11,12,15,19}\": true\n  }, \"# Apply a configuration to a resource by filename or stdin. The resource name must be specified. This resource will be created if it doesn't exist yet. JSON and YAML formats are accepted.\\n$ kubectl apply -f pod/pod.yaml\\npod/twocontainers created\\n\\n# List the pods\\n$ kubectl get pods -o wide\\nNAME            READY   STATUS    RESTARTS   AGE   IP          NODE                                            NOMINATED NODE\\ntwocontainers   2/2     Running   0          1m    10.12.1.7   gke-k8s-by-example-default-pool-f7f7edae-09cs   <none>\\n\\n# Get inside the container named 'shell' within the pod named 'twocontainers'\\n$ kubectl exec -it twocontainers -c shell -- bash\\n[root@twocontainers /]# curl localhost:9876/info\\n{\\\"host\\\": \\\"localhost:9876\\\", \\\"version\\\": \\\"0.5.0\\\", \\\"from\\\": \\\"127.0.0.1\\\"}\\n\\n[root@twocontainers /]# curl 10.12.1.7:9876/info\\n{\\\"host\\\": \\\"10.12.1.7:9876\\\", \\\"version\\\": \\\"0.5.0\\\", \\\"from\\\": \\\"10.12.1.7\\\"}\\n\\n# Clean up\\n$ kubectl delete pods twocontainers\\npod \\\"twocontainers\\\" deleted\\n\")), mdx(\"h5\", null, \"Creating pods with resource limits\"), mdx(\"p\", null, \"Set the cpu and memory limits at \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"spec.containers[].resources.limits.cpu\"), \" and \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"spec.containers[].resources.limits.memory\"), \" respectively.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-yaml:title=Basics/04-Kubernetes-By-Example/pod/constraint-pod.yaml\",\n    \"metastring\": \"{11-14}\",\n    \"{11-14}\": true\n  }, \"apiVersion: v1\\nkind: Pod\\nmetadata:\\n  name: containers-constraint\\nspec:\\n  containers:\\n  - name: sise\\n    image: mhausenblas/simpleservice:0.5.0\\n    ports:\\n    - containerPort: 9876\\n    resources:\\n      limits:\\n        memory: \\\"64Mi\\\"\\n        cpu: \\\"500m\\\"\\n\")), mdx(\"p\", null, \"Create the pod with the resource limits set above\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2,5,10}\",\n    \"{2,5,10}\": true\n  }, \"# Create the pod\\nkubectl apply -f pod/constraint-pod.yaml\\n\\n# List the pods\\n$ kubectl get pods\\nNAME                    READY   STATUS    RESTARTS   AGE\\ncontainers-constraint   1/1     Running   0          14m\\n\\n# Clean up\\n$ kubectl delete pods containers-constraint\\npod \\\"containers-constraint\\\" deleted\\n\")), mdx(\"p\", null, \"[\", mdx(\"sub\", null, mdx(\"sup\", null, mdx(\"a\", {\n    href: \"#top-contents\"\n  }, \"GO TO TOP\"))), \"]\"), mdx(\"h3\", null, \"Labels \", mdx(\"a\", {\n    id: \"labels\"\n  })), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"Labels are the mechanism you use to organize Kubernetes objects. A label is a key-value pair with certain restrictions concerning length and allowed values but without any pre-defined meaning.\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2,6}\",\n    \"{2,6}\": true\n  }, \"# Create the pod using labels/labels-1.yaml\\n$ kubectl create -f labels/labels-1.yaml\\npod/labelex created\\n\\n# Check the pods created\\n$ kubectl get pods\\nNAME      READY   STATUS             RESTARTS   AGE\\nlabelex   0/1     ImagePullBackOff   0          31s\\n\")), mdx(\"p\", null, \"Oops! Looks like I made some mistake while specifying the image for the container. Let me checkout what went wrong using the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"describe\"), \" command:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{1}\",\n    \"{1}\": true\n  }, \"$ kubectl describe pods labelex\\nName:               labelex\\nNamespace:          default\\nPriority:           0\\nPriorityClassName:  <none>\\nNode:               gke-k8s-by-example-default-pool-41076e94-4n53/10.160.0.12\\nStart Time:         Fri, 15 Mar 2019 18:12:37 +0530\\nLabels:             env=development\\nAnnotations:        <none>\\nStatus:             Pending\\nIP:                 10.12.2.8\\n.\\n.\\n.\\nEvents:\\n  Type     Reason          Age                   From                                                    Message\\n  ----     ------          ----                  ----                                                    -------\\n  Normal   Scheduled       5m10s                 default-scheduler                                       Successfully assigned default/labelex to gke-k8s-by-example-default-pool-41076e94-4n53\\n  Normal   SandboxChanged  5m1s (x2 over 5m3s)   kubelet, gke-k8s-by-example-default-pool-41076e94-4n53  Pod sandbox changed, it will be killed and re-created.\\n  Normal   Pulling         4m10s (x3 over 5m9s)  kubelet, gke-k8s-by-example-default-pool-41076e94-4n53  pulling image \\\"mhausenblas/simpleservice:0.5.\\\"\\n  Warning  Failed          4m5s (x3 over 5m4s)   kubelet, gke-k8s-by-example-default-pool-41076e94-4n53  Failed to pull image \\\"mhausenblas/simpleservice:0.5.\\\": rpc error: code = Unknown desc = Error response from daemon: manifest for mhausenblas/simpleservice:0.5. not found\\n  Warning  Failed          4m5s (x3 over 5m4s)   kubelet, gke-k8s-by-example-default-pool-41076e94-4n53  Error: ErrImagePull\\n  Normal   BackOff         3m26s (x7 over 5m2s)  kubelet, gke-k8s-by-example-default-pool-41076e94-4n53  Back-off pulling image \\\"mhausenblas/simpleservice:0.5.\\\"\\n  Warning  Failed          3s (x19 over 5m2s)    kubelet, gke-k8s-by-example-default-pool-41076e94-4n53  Error: ImagePullBackOff\\n\")), mdx(\"p\", null, \"Skimming through the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Events\"), \" section I found:\"), mdx(\"p\", null, mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Failed to pull image \\\"mhausenblas/simpleservice:0.5.\\\": rpc error: code = Unknown desc = Error response from daemon: manifest for mhausenblas/simpleservice:0.5. not found\")), mdx(\"p\", null, \"Lol! I mentioned the wrong image name(\", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"mhausenblas/simpleservice:0.5.\"), \" instead of \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"mhausenblas/simpleservice:0.5.0\"), \"). Let me correct that and apply the changes:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2,9,14,19,24,28,33}\",\n    \"{2,9,14,19,24,28,33}\": true\n  }, \"# This time the image is successfully pulled\\n$ kubectl describe pods labelex\\n# Events:\\n#  Type     Reason          Age                   From                                                    Message\\n#   ----     ------          ----                  ----                                                    -------\\n#  Normal   Pulled          68s                   kubelet, gke-k8s-by-example-default-pool-41076e94-4n53  Successfully pulled image \\\"mhausenblas/simpleservice:0.5.0\\\"\\n\\n# List the pod created\\n$ kubectl get pods\\nNAME      READY   STATUS    RESTARTS   AGE\\nlabelex   1/1     Running   0          11m\\n\\n# Show the labels as well\\n$ kubectl get pods --show-labels\\nNAME      READY   STATUS    RESTARTS   AGE   LABELS\\nlabelex   1/1     Running   0          15m   env=development\\n\\n# Filter by the label now\\n$ kubectl get pods -l env=development\\nNAME      READY   STATUS    RESTARTS   AGE\\nlabelex   1/1     Running   0          16m\\n\\n# Add a label to the pod\\n$ kubectl label pods labelex ownwer=bensooraj\\npod/labelex labeled\\n\\n# List them out again\\n$ kubectl get pods --show-labels\\nNAME      READY   STATUS    RESTARTS   AGE   LABELS\\nlabelex   1/1     Running   0          17m   env=development,ownwer=bensooraj\\n\\n# Filter by the new label.\\n$ kubectl get pods --selector ownwer=bensooraj\\nNAME      READY   STATUS    RESTARTS   AGE\\nlabelex   1/1     Running   0          19m\\n\\n\")), mdx(\"p\", null, \"I am really sorry for the spelling mistake with the label \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"ownwer=bensooraj\"), \". It hurts my eyes.\"), mdx(\"p\", null, \"Anyways, \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"--selector\"), \" and \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"-l\"), \" mean the same thing.\"), mdx(\"h4\", null, \"Set based selectors\"), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"Kubernetes objects also support set-based selectors\")), mdx(\"p\", null, \"We will launch another pod that has two labels (env=production and owner=bensooraj)\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2,5,11,16}\",\n    \"{2,5,11,16}\": true\n  }, \"# Create a new pod using labels/labels-2.yaml\\n$ kubectl apply -f labels/labels-2.yaml\\n\\n# List out all the pods along with the labels\\n$ kubectl get pods --show-labels\\nNAME       READY   STATUS    RESTARTS   AGE   LABELS\\nlabelex    1/1     Running   0          57m   env=development,ownwer=bensooraj\\nlabelex2   1/1     Running   0          2m    env=production,owner=bensooraj\\n\\n# Let's get fancy here with selecting the labels\\n$ kubectl get pods --show-labels -l 'env in (development)'\\nNAME      READY   STATUS    RESTARTS   AGE   LABELS\\nlabelex   1/1     Running   0          57m   env=development,ownwer=bensooraj\\n\\n# The following lists all pods that are either labelled with env=development or with env=production\\n$ kubectl get pods --show-labels -l 'env in (development, production)'\\nNAME       READY   STATUS    RESTARTS   AGE   LABELS\\nlabelex    1/1     Running   0          57m   env=development,ownwer=bensooraj\\nlabelex2   1/1     Running   0          3m    env=production,owner=bensooraj\\n\")), mdx(\"p\", null, \"I can even delete pods like that:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{1,6}\",\n    \"{1,6}\": true\n  }, \"$ kubectl delete pods -l 'env in (development, production)'\\npod \\\"labelex\\\" deleted\\npod \\\"labelex2\\\" deleted\\n\\n# You can see them getting terminated\\n$ kubectl get pods -w\\nNAME       READY   STATUS        RESTARTS   AGE\\nlabelex    1/1     Terminating   0          61m\\nlabelex2   1/1     Terminating   0          6m34s\\n\")), mdx(\"p\", null, \"[\", mdx(\"sub\", null, mdx(\"sup\", null, mdx(\"a\", {\n    href: \"#top-contents\"\n  }, \"GO TO TOP\"))), \"]\"), mdx(\"h3\", null, \"Deployments \", mdx(\"a\", {\n    id: \"deployments\"\n  })), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"A deployment is a supervisor for pods, giving you fine-grained control over how and when a new pod version is rolled out as well as rolled back to a previous state.\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2,6,12,18,23}\",\n    \"{2,6,12,18,23}\": true\n  }, \"# Create a deploment called sise-deploy using\\n$ kubectl apply -f deployments/deployment-1.yaml\\ndeployment.apps/sise-deployment created\\n\\n# The deployment has started creating the pods\\n$ kubectl get pods\\nNAME                               READY   STATUS              RESTARTS   AGE\\nsise-deployment-6b9688f8f5-8xgr4   0/1     ContainerCreating   0          25s\\nsise-deployment-6b9688f8f5-cwlvc   0/1     ContainerCreating   0          25s\\n\\n# After a while\\n$ kubectl get pods\\nNAME                               READY   STATUS    RESTARTS   AGE\\nsise-deployment-6b9688f8f5-8xgr4   1/1     Running   0          63s\\nsise-deployment-6b9688f8f5-cwlvc   1/1     Running   0          63s\\n\\n# Check the deployment as well\\n$ kubectl get deployments -o wide\\nNAME              DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES                            SELECTOR\\nsise-deployment   2         2         2            2           3m    sise         mhausenblas/simpleservice:0.5.0   app=sise\\n\\n# List out the replica sets\\n$ kubectl get rs -o wide\\nNAME                         DESIRED   CURRENT   READY   AGE   CONTAINERS   IMAGES                            SELECTOR\\nsise-deployment-6b9688f8f5   2         2         2       4m    sise         mhausenblas/simpleservice:0.5.0   app=sise,pod-template-hash=2652449491\\n\")), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"Note the naming of the pods and replica set, derived from the deployment name.\")), mdx(\"p\", null, \"Check the app using the pod IPs\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2,5}\",\n    \"{2,5}\": true\n  }, \"# Get the pod IPs\\n$ kubectl describe pod sise-deployment-6b9688f8f5-8xgr4 | grep IP\\nIP:                 10.12.1.6\\n\\n$ kubectl describe pod sise-deployment-6b9688f8f5-cwlvc | grep IP\\nIP:                 10.12.2.5\\n\")), mdx(\"p\", null, \"SSH into one of the nodes of the cluster:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Navigate to \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"GCE > Compute Engine > VM instances\"), \". Select one of the nodes\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Under the \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"Connect\"), \" (against any one of the nodes), click on the \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"SSH\"), \" drop-down and select \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"View gcloud command\"), \" as shown below:\\n\", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"960px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"33.33333333333333%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAABYlAAAWJQFJUiTwAAABHUlEQVQoz11R2W6DQAzc//8tpL61idIKNU3YquHIEo4A4b6mGSOatitZNt6Z8eBVfdeirmt0XYd5nsGz5t818zRN+H/YJzdJEskqvbVSDMMguSxLNE2DMAyRpqn0mPu+xziOQszzHEVRCIY83vObA9XT5hlvu1fYto04juG6rhDieCGSZFkW9vu9iIUmlN71eoUxBsUdEwQGUZLfjdRQH59HmLMREN1RpG0frrMsk2Hu6QTtaGit4TiOiNMZsTzEs1bv+iBgz/OkQUHuZd1dWd6wednIPYfS1eqSNf+KQS45SgdfOAdnAbBZVdUfQT4YnZFMZwyuZX2gFcv9MtTBOeISXhBFkdhelvsQ5IDtdgvf90VkWUX/I7AG78j5BgYNFp+2x5S/AAAAAElFTkSuQmCC')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Deployment 1\",\n    \"title\": \"Deployment 1\",\n    \"src\": \"/static/15cfd0d12f0ea3b1125be0b9e8ab029e/7d769/deploy-1.png\",\n    \"srcSet\": [\"/static/15cfd0d12f0ea3b1125be0b9e8ab029e/5243c/deploy-1.png 240w\", \"/static/15cfd0d12f0ea3b1125be0b9e8ab029e/ab158/deploy-1.png 480w\", \"/static/15cfd0d12f0ea3b1125be0b9e8ab029e/7d769/deploy-1.png 960w\", \"/static/15cfd0d12f0ea3b1125be0b9e8ab029e/87339/deploy-1.png 1440w\", \"/static/15cfd0d12f0ea3b1125be0b9e8ab029e/c5a59/deploy-1.png 1668w\"],\n    \"sizes\": \"(max-width: 960px) 100vw, 960px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n    \")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"You will be presented with a command similar to: \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"gcloud compute --project \\\"kubernetes-practice-219913\\\" ssh --zone \\\"asia-south1-a\\\" \\\"gke-k8s-by-example-default-pool-5574bdde-7k75\\\"\"))), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2,5}\",\n    \"{2,5}\": true\n  }, \"# From within the cluster, access the app running inside the pods\\nBensooraj@gke-k8s-by-example-default-pool-5574bdde-7k75 ~ $ curl 10.12.1.6:9876/info\\n{\\\"host\\\": \\\"10.12.1.6:9876\\\", \\\"version\\\": \\\"0.9\\\", \\\"from\\\": \\\"10.160.0.13\\\"}\\n\\nBensooraj@gke-k8s-by-example-default-pool-5574bdde-7k75 ~ $ curl 10.12.2.5:9876/info\\n{\\\"host\\\": \\\"10.12.2.5:9876\\\", \\\"version\\\": \\\"0.9\\\", \\\"from\\\": \\\"10.160.0.13\\\"}\\n\")), mdx(\"p\", null, \"Rolling out an update\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2,6,14,20,26}\",\n    \"{2,6,14,20,26}\": true\n  }, \"# Update the value of the environment variable SIMPLE_SERVICE_VERSION from \\\"0.9\\\" to \\\"1.0\\\"\\n$ kubectl apply -f deployments/deployment-2.yaml\\ndeployment.apps/sise-deployment configured\\n\\n# You can see the roll-out happening\\n$ kubectl get pods -w\\nNAME                               READY   STATUS        RESTARTS   AGE\\nsise-deployment-6b9688f8f5-8xgr4   1/1     Terminating   0          41m\\nsise-deployment-6b9688f8f5-cwlvc   1/1     Terminating   0          41m\\nsise-deployment-6c7b7f88c5-8mwr2   1/1     Running       0          16s\\nsise-deployment-6c7b7f88c5-zxfgm   1/1     Running       0          18s\\n\\n# After a while\\n$ kubectl get pods\\nNAME                               READY   STATUS    RESTARTS   AGE\\nsise-deployment-6c7b7f88c5-8mwr2   1/1     Running   0          2m\\nsise-deployment-6c7b7f88c5-zxfgm   1/1     Running   0          2m\\n\\n# Check out the replication set as well. A new replication set will be created\\n$ kubectl get rs -w\\nNAME                         DESIRED   CURRENT   READY   AGE\\nsise-deployment-6b9688f8f5   0         0         0       42m\\nsise-deployment-6c7b7f88c5   2         2         2       57s\\n\\n# Check out the roll-out status\\n$ kubectl rollout status deployment sise-deployment\\ndeployment \\\"sise-deployment\\\" successfully rolled out\\n\")), mdx(\"p\", null, \"Remember, the value change can also be rolled out using the command: \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"kubectl edit deploy sise-deployment\"), \".\"), mdx(\"p\", null, \"Verify the change made to the value of the environment variable by pinging the app\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2,5,9,12}\",\n    \"{2,5,9,12}\": true\n  }, \"# Get the new set of pod IPs\\n$ kubectl describe pods sise-deployment-6c7b7f88c5-8mwr2 | grep IP\\nIP:                 10.12.2.6\\n\\n$ kubectl describe pods sise-deployment-6c7b7f88c5-zxfgm | grep IP\\nIP:                 10.12.1.7\\n\\n# Curl the IPs from the node we SSHed into above\\nBensooraj@gke-k8s-by-example-default-pool-5574bdde-7k75 ~ $ curl 10.12.2.6:9876/info\\n{\\\"host\\\": \\\"10.12.2.6:9876\\\", \\\"version\\\": \\\"1.0\\\", \\\"from\\\": \\\"10.160.0.13\\\"}\\n\\nBensooraj@gke-k8s-by-example-default-pool-5574bdde-7k75 ~ $ curl 10.12.1.7:9876/info\\n{\\\"host\\\": \\\"10.12.1.7:9876\\\", \\\"version\\\": \\\"1.0\\\", \\\"from\\\": \\\"10.160.0.13\\\"}\\n\")), mdx(\"p\", null, \"Undo the roll-out\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2,9,13,21,28,31,35,38}\",\n    \"{2,9,13,21,28,31,35,38}\": true\n  }, \"# Check-out the roll-out history\\n$ kubectl rollout history deployment sise-deployment\\ndeployment.extensions/sise-deployment\\nREVISION  CHANGE-CAUSE\\n1         <none>\\n2         <none>\\n\\n# Undo the roll-out\\n$ kubectl rollout undo deployment sise-deployment\\ndeployment.extensions/sise-deployment\\n\\n# The roll-back has begun\\n$ kubectl get pods -o wide -w\\nNAME                               READY   STATUS        RESTARTS   AGE   IP          NODE                                            NOMINATED NODE\\nsise-deployment-6b9688f8f5-74fnz   1/1     Running       0          8s    10.12.2.7   gke-k8s-by-example-default-pool-5574bdde-gkhk   <none>\\nsise-deployment-6b9688f8f5-gglnk   1/1     Running       0          10s   10.12.1.8   gke-k8s-by-example-default-pool-5574bdde-dnnl   <none>\\nsise-deployment-6c7b7f88c5-8mwr2   1/1     Terminating   0          13m   10.12.2.6   gke-k8s-by-example-default-pool-5574bdde-gkhk   <none>\\nsise-deployment-6c7b7f88c5-zxfgm   1/1     Terminating   0          13m   10.12.1.7   gke-k8s-by-example-default-pool-5574bdde-dnnl   <none>\\n\\n# List the roll-out history one more time\\n$ kubectl rollout history deployment sise-deployment\\ndeployment.extensions/sise-deployment\\nREVISION  CHANGE-CAUSE\\n2         <none>\\n3         <none>\\n\\n# Get the new IP addresses\\n$ kubectl describe pods sise-deployment-6b9688f8f5-74fnz | grep IP\\nIP:                 10.12.2.7\\n\\n$ kubectl describe pods sise-deployment-6b9688f8f5-gglnk | grep IP\\nIP:                 10.12.1.8\\n\\n# Ping the app again from withing the cluster\\nBensooraj@gke-k8s-by-example-default-pool-5574bdde-7k75 ~ $ curl 10.12.2.7:9876/info\\n{\\\"host\\\": \\\"10.12.2.7:9876\\\", \\\"version\\\": \\\"0.9\\\", \\\"from\\\": \\\"10.160.0.13\\\"}\\n\\nBensooraj@gke-k8s-by-example-default-pool-5574bdde-7k75 ~ $ curl 10.12.1.8:9876/info\\n{\\\"host\\\": \\\"10.12.1.8:9876\\\", \\\"version\\\": \\\"0.9\\\", \\\"from\\\": \\\"10.160.0.13\\\"}\\n\")), mdx(\"p\", null, \"You can see the version rolled-back from \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"\\\"version\\\": \\\"1.0\\\"\"), \" to \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"\\\"version\\\": \\\"0.9\\\"\"), \".\"), mdx(\"p\", null, \"Also, you can explicitly roll back to a specific revision using the flag \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"--to-revision\"), \". For example: \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"kubectl rollout undo deployment sise-deployment\")), mdx(\"p\", null, \"Time to clean up!\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{1,5}\",\n    \"{1,5}\": true\n  }, \"$ kubectl delete deployment sise-deployment\\ndeployment.extensions \\\"sise-deployment\\\" deleted\\n\\n# Pods going down! :P\\n$ kubectl get pods -w\\nNAME                               READY   STATUS        RESTARTS   AGE\\nsise-deployment-6b9688f8f5-74fnz   1/1     Terminating   0          6m27s\\nsise-deployment-6b9688f8f5-gglnk   1/1     Terminating   0          6m29s\\n\")), mdx(\"p\", null, \"[\", mdx(\"sub\", null, mdx(\"sup\", null, mdx(\"a\", {\n    href: \"#top-contents\"\n  }, \"GO TO TOP\"))), \"]\"), mdx(\"h3\", null, \"Services \", mdx(\"a\", {\n    id: \"services\"\n  })), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"A service is an abstraction for pods, providing a stable, so called virtual IP (\", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"VIP\"), \") address. While pods may come and go and with it their IP addresses, a service allows clients to reliably connect to the containers running in the pod using the VIP. The \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"virtual\"), \" in VIP means it is not an actual IP address connected to a network interface, but its purpose is purely to forward traffic to one or more pods. Keeping the mapping between the VIP and the pods up-to-date is the job of \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"kube-proxy\"), \", a process that runs on every node, which queries the API server to learn about new services in the cluster.\")), mdx(\"p\", null, \"Create the ReplicationController from \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"rc.yaml\"), \":\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{1,4,9}\",\n    \"{1,4,9}\": true\n  }, \"$ kubectl apply -f services/rc.yaml\\n\\n# Check the ReplicationController created\\n$ kubectl get replicationcontrollers -o wide\\nNAME      DESIRED   CURRENT   READY   AGE   CONTAINERS   IMAGES                            SELECTOR\\nrc-sise   2         2         2       50s   rc-sise      mhausenblas/simpleservice:0.5.0   app=rc-sise\\n\\n# And the pods\\n$ kubectl get pod --show-labels -o wide\\nNAME            READY   STATUS    RESTARTS   AGE   IP          NODE                                            NOMINATED NODE   LABELS\\nrc-sise-24vg4   1/1     Running   0          1m    10.12.1.9   gke-k8s-by-example-default-pool-5574bdde-dnnl   <none>           app=rc-sise\\nrc-sise-dm4p8   1/1     Running   0          1m    10.12.2.8   gke-k8s-by-example-default-pool-5574bdde-gkhk   <none>           app=rc-sise\\n\")), mdx(\"p\", null, \"Create the Service from \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"svc.yaml\"), \":\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{1,5,11,17}\",\n    \"{1,5,11,17}\": true\n  }, \"$ kubectl apply -f services/svc.yaml\\nservice/simple-service created\\n\\n# Get the service\\n$ kubectl get service -o wide\\nNAME             TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE   SELECTOR\\nkubernetes       ClusterIP   10.15.240.1     <none>        443/TCP   3h    <none>\\nsimple-service   ClusterIP   10.15.255.188   <none>        80/TCP    29s   app=rc-sise\\n\\n# Get the pods\\n$ kubectl get pods -l app=rc-sise -o wide\\nNAME            READY   STATUS    RESTARTS   AGE   IP          NODE                                            NOMINATED NODE\\nrc-sise-24vg4   1/1     Running   0          7m    10.12.1.9   gke-k8s-by-example-default-pool-5574bdde-dnnl   <none>\\nrc-sise-dm4p8   1/1     Running   0          7m    10.12.2.8   gke-k8s-by-example-default-pool-5574bdde-gkhk   <none>\\n\\n# Describe one of the pods and grab one of their IPs\\n$ kubectl describe pods rc-sise-24vg4 | grep IP\\nIP:                 10.12.1.9\\n\\n# This can be accessed from one of three nodes running in the cluster\\nBensooraj@gke-k8s-by-example-default-pool-5574bdde-7k75 ~ $ curl 10.12.1.9:9876/info\\n{\\\"host\\\": \\\"10.12.1.9:9876\\\", \\\"version\\\": \\\"0.5.0\\\", \\\"from\\\": \\\"10.160.0.13\\\"}\\n\")), mdx(\"p\", null, \"However, remember that pod IPs are ephemeral in nature and exist only as long as the pod exists. So, relying on pod IPs is not the right approach.\"), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"The service keeps track of the pods it forwards traffic to through the label, in our case \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"app=sise\"), \".\")), mdx(\"p\", null, \"Let's review the service that we created one more time:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{1,7}\",\n    \"{1,7}\": true\n  }, \"$ kubectl get svc -o wide\\nNAME             TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE   SELECTOR\\nkubernetes       ClusterIP   10.15.240.1     <none>        443/TCP   3h    <none>\\nsimple-service   ClusterIP   10.15.255.188   <none>        80/TCP    6m    app=rc-sise\\n\\n# Describe them\\n$ kubectl describe svc simple-service\\nName:              simple-service\\nNamespace:         default\\nLabels:            <none>\\nAnnotations:       kubectl.kubernetes.io/last-applied-configuration:\\n                     {\\\"apiVersion\\\":\\\"v1\\\",\\\"kind\\\":\\\"Service\\\",\\\"metadata\\\":{\\\"annotations\\\":{},\\\"name\\\":\\\"simple-service\\\",\\\"namespace\\\":\\\"default\\\"},\\\"spec\\\":{\\\"ports\\\":[{\\\"port\\\":8...\\nSelector:          app=rc-sise\\nType:              ClusterIP\\nIP:                10.15.255.188\\nPort:              <unset>  80/TCP\\nTargetPort:        9876/TCP\\nEndpoints:         10.12.1.9:9876,10.12.2.8:9876\\nSession Affinity:  None\\nEvents:            <none>\\n\")), mdx(\"p\", null, \"Note that the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Endpoints\"), \" are actually pod IPs along with the port on which the application is running.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2}\",\n    \"{2}\": true\n  }, \"# The application can now be accessed using the clusterIP, from within the cluster\\nBensooraj@gke-k8s-by-example-default-pool-5574bdde-7k75 ~ $ curl 10.15.255.188/info\\n{\\\"host\\\": \\\"10.15.255.188\\\", \\\"version\\\": \\\"0.5.0\\\", \\\"from\\\": \\\"10.160.0.13\\\"}\\n\")), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://wiki.centos.org/HowTos/Network/IPTables\"\n  }, mdx(\"inlineCode\", {\n    parentName: \"a\"\n  }, \"IPtables\")), \" makes the VIP \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"10.15.255.188\"), \" forward the traffic to the pods. \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"IPtables\"), \" is a long list of rules that tells the Linux kernel what to do with a certain IP package.\")), mdx(\"p\", null, \"Let's check them out:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2}\",\n    \"{2}\": true\n  }, \"# From within the cluster, that is from within a node(vm) running in the cluster\\nBensooraj@gke-k8s-by-example-default-pool-5574bdde-7k75 ~ $ sudo iptables-save | grep simple-service\\n\\n-A KUBE-SEP-XKHKNSMBAPANOQ3H -s 10.12.1.9/32 -m comment --comment \\\"default/simple-service:\\\" -j KUBE-MARK-MASQ\\n-A KUBE-SEP-XKHKNSMBAPANOQ3H -p tcp -m comment --comment \\\"default/simple-service:\\\" -m tcp -j DNAT --to-destination 10.12.1.9:9876\\n-A KUBE-SEP-XRG5PL6H4OXP3HUZ -s 10.12.2.8/32 -m comment --comment \\\"default/simple-service:\\\" -j KUBE-MARK-MASQ\\n-A KUBE-SEP-XRG5PL6H4OXP3HUZ -p tcp -m comment --comment \\\"default/simple-service:\\\" -m tcp -j DNAT --to-destination 10.12.2.8:9876\\n-A KUBE-SERVICES ! -s 10.12.0.0/14 -d 10.15.255.188/32 -p tcp -m comment --comment \\\"default/simple-service: cluster IP\\\" -m tcp --dport 80 -j KUBE-MARK-MASQ\\n-A KUBE-SERVICES -d 10.15.255.188/32 -p tcp -m comment --comment \\\"default/simple-service: cluster IP\\\" -m tcp --dport 80 -j KUBE-SVC-LRSQWG6IZCA6IBBJ\\n-A KUBE-SVC-LRSQWG6IZCA6IBBJ -m comment --comment \\\"default/simple-service:\\\" -m statistic --mode random --probability 0.50000000000 -j KUBE-SEP-XKHKNSMBAPANOQ3H\\n-A KUBE-SVC-LRSQWG6IZCA6IBBJ -m comment --comment \\\"default/simple-service:\\\" -j KUBE-SEP-XRG5PL6H4OXP3HUZ\\n\")), mdx(\"p\", null, \"I have no clue how to read the above table, however, this is the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"kube-proxy\"), \" defining rules to allow TCP connections back-n-forth the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"ClusterIP\"), \" \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"10.15.255.188\"), \" and the pod IPs \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"10.12.1.9:9876\"), \" and \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"10.12.2.8:9876\"), \".\"), mdx(\"p\", null, \"Let's scale up our \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"ReplicationController\"), \":\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{1,5}\",\n    \"{1,5}\": true\n  }, \"$ kubectl scale replicationcontroller --replicas=3 rc-sise\\nreplicationcontroller/rc-sise scaled\\n\\n# Check the pods\\n$ kubectl get pods --show-labels -o wide -w\\nNAME            READY   STATUS    RESTARTS   AGE   IP           NODE                                            NOMINATED NODE   LABELS\\nrc-sise-24vg4   1/1     Running   0          29m   10.12.1.9    gke-k8s-by-example-default-pool-5574bdde-dnnl   <none>           app=rc-sise\\nrc-sise-dm4p8   1/1     Running   0          29m   10.12.2.8    gke-k8s-by-example-default-pool-5574bdde-gkhk   <none>           app=rc-sise\\nrc-sise-p7sk9   1/1     Running   0          14s   10.12.1.10   gke-k8s-by-example-default-pool-5574bdde-dnnl   <none>           app=rc-sise\\n\")), mdx(\"p\", null, \"We have one more pod IP to handle, \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"10.12.1.10\"), \".\"), mdx(\"p\", null, \"And guess what? The service \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"simple-service\"), \" has already updated itself to account for the 3rd pod added to the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"ReplicationController\"), \".\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2}\",\n    \"{2}\": true\n  }, \"# Check the Endpoints key. All the 3 pod IPs are now handled by the service\\n$ kubectl describe service simple-service\\nName:              simple-service\\nNamespace:         default\\nLabels:            <none>\\nAnnotations:       kubectl.kubernetes.io/last-applied-configuration:\\n                     {\\\"apiVersion\\\":\\\"v1\\\",\\\"kind\\\":\\\"Service\\\",\\\"metadata\\\":{\\\"annotations\\\":{},\\\"name\\\":\\\"simple-service\\\",\\\"namespace\\\":\\\"default\\\"},\\\"spec\\\":{\\\"ports\\\":[{\\\"port\\\":8...\\nSelector:          app=rc-sise\\nType:              ClusterIP\\nIP:                10.15.255.188\\nPort:              <unset>  80/TCP\\nTargetPort:        9876/TCP\\nEndpoints:         10.12.1.10:9876,10.12.1.9:9876,10.12.2.8:9876\\nSession Affinity:  None\\nEvents:            <none>\\n\")), mdx(\"p\", null, \"Let's also checkout the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"IPtables\"), \" as well from within the cluster:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{1}\",\n    \"{1}\": true\n  }, \"Bensooraj@gke-k8s-by-example-default-pool-5574bdde-7k75 ~ $ sudo iptables-save | grep simple-service\\n\\n-A KUBE-SEP-O5OGXTSGDHX72GHE -s 10.12.1.10/32 -m comment --comment \\\"default/simple-service:\\\" -j KUBE-MARK-MASQ\\n-A KUBE-SEP-O5OGXTSGDHX72GHE -p tcp -m comment --comment \\\"default/simple-service:\\\" -m tcp -j DNAT --to-destination 10.12.1.10:9876\\n-A KUBE-SEP-XKHKNSMBAPANOQ3H -s 10.12.1.9/32 -m comment --comment \\\"default/simple-service:\\\" -j KUBE-MARK-MASQ\\n-A KUBE-SEP-XKHKNSMBAPANOQ3H -p tcp -m comment --comment \\\"default/simple-service:\\\" -m tcp -j DNAT --to-destination 10.12.1.9:9876\\n-A KUBE-SEP-XRG5PL6H4OXP3HUZ -s 10.12.2.8/32 -m comment --comment \\\"default/simple-service:\\\" -j KUBE-MARK-MASQ\\n-A KUBE-SEP-XRG5PL6H4OXP3HUZ -p tcp -m comment --comment \\\"default/simple-service:\\\" -m tcp -j DNAT --to-destination 10.12.2.8:9876\\n-A KUBE-SERVICES ! -s 10.12.0.0/14 -d 10.15.255.188/32 -p tcp -m comment --comment \\\"default/simple-service: cluster IP\\\" -m tcp --dport 80 -j KUBE-MARK-MASQ\\n-A KUBE-SERVICES -d 10.15.255.188/32 -p tcp -m comment --comment \\\"default/simple-service: cluster IP\\\" -m tcp --dport 80 -j KUBE-SVC-LRSQWG6IZCA6IBBJ\\n-A KUBE-SVC-LRSQWG6IZCA6IBBJ -m comment --comment \\\"default/simple-service:\\\" -m statistic --mode random --probability 0.33332999982 -j KUBE-SEP-O5OGXTSGDHX72GHE\\n-A KUBE-SVC-LRSQWG6IZCA6IBBJ -m comment --comment \\\"default/simple-service:\\\" -m statistic --mode random --probability 0.50000000000 -j KUBE-SEP-XKHKNSMBAPANOQ3H\\n-A KUBE-SVC-LRSQWG6IZCA6IBBJ -m comment --comment \\\"default/simple-service:\\\" -j KUBE-SEP-XRG5PL6H4OXP3HUZ\\n\")), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"... the traffic to the service is equally split between the three pods by invoking the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"statistics\"), \" module of \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"IPtables\"), \".\")), mdx(\"p\", null, \"I think the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"--probability\"), \" does that.\"), mdx(\"p\", null, \"Alrighty! Time to clean up:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{1,4}\",\n    \"{1,4}\": true\n  }, \"$ kubectl delete replicationcontrollers rc-sise\\nreplicationcontroller \\\"rc-sise\\\" deleted\\n\\n$ kubectl delete svc simple-service\\nservice \\\"simple-service\\\" deleted\\n\")), mdx(\"p\", null, \"I think it makes more sense to delete the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Service\"), \" first and then the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"ReplicationController\"), \". I will do that next time.\"), mdx(\"p\", null, \"[\", mdx(\"sub\", null, mdx(\"sup\", null, mdx(\"a\", {\n    href: \"#top-contents\"\n  }, \"GO TO TOP\"))), \"]\"), mdx(\"h3\", null, \"Service Discovery \", mdx(\"a\", {\n    id: \"service-discovery\"\n  })), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"Service discovery is the process of figuring out how to connect to a service. While there is a service discovery option based on environment variables available, the DNS-based service discovery is preferable. Note that DNS is a cluster add-on so make sure your Kubernetes distribution provides for one or install it yourself.\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2,6,12,16}\",\n    \"{2,6,12,16}\": true\n  }, \"# Create the RC from service-discovery/rc.yaml\\n$ kubectl apply -f service-discovery/rc.yaml\\nreplicationcontroller/rcsise created\\n\\n# Check the pods\\n$ kubectl get pods -o wide\\nNAME           READY   STATUS    RESTARTS   AGE   IP          NODE                                            NOMINATED NODE\\nrcsise-mgdc8   1/1     Running   0          56s   10.12.2.6   gke-k8s-by-example-default-pool-dec3a359-jsgl   <none>\\nrcsise-rwqxt   1/1     Running   0          56s   10.12.1.5   gke-k8s-by-example-default-pool-dec3a359-wrxk   <none>\\n\\n# Create the service as well using service-discovery/svc.yaml\\n$ kubectl apply -f service-discovery/svc.yaml\\nservice/thesvc created\\n\\n# Check the service that we just created\\n$ kubectl get svc -o wide -w\\nNAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE    SELECTOR\\nkubernetes   ClusterIP   10.15.240.1     <none>        443/TCP   159m   <none>\\nthesvc       ClusterIP   10.15.241.194   <none>        80/TCP    11s    app=sise\\n\")), mdx(\"p\", null, \"I will now create a \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"jump pod\"), \" in the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"default\"), \" namespace and try to simulate connecting to the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"thesvc\"), \" service from within the cluster, say, from another service.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2,6}\",\n    \"{2,6}\": true\n  }, \"# Create the jump pod\\n$ kubectl apply -f service-discovery/jumppod.yaml\\npod/jumppod created\\n\\n# List the pods created\\n$ kubectl get pods -o wide\\nNAME           READY   STATUS    RESTARTS   AGE   IP          NODE                                            NOMINATED NODE\\njumppod        1/1     Running   0          1m    10.12.2.7   gke-k8s-by-example-default-pool-dec3a359-jsgl   <none>\\nrcsise-mgdc8   1/1     Running   0          31m   10.12.2.6   gke-k8s-by-example-default-pool-dec3a359-jsgl   <none>\\nrcsise-rwqxt   1/1     Running   0          31m   10.12.1.5   gke-k8s-by-example-default-pool-dec3a359-wrxk   <none>\\n\")), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"The DNS add-on will make sure that our service \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"thesvc\"), \" is available via the FQDN \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"thesvc.default.svc.cluster.local\"), \" from other pods in the cluster.\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2,5}\",\n    \"{2,5}\": true\n  }, \"# Get inside the pod `jumppod`\\n$ kubectl exec -it jumppod sh\\n\\n# From within jumppod, ping thesvc.default.svc.cluster.local\\nsh-4.2# ping thesvc.default.svc.cluster.local\\nPING thesvc.default.svc.cluster.local (10.15.241.194) 56(84) bytes of data.\\n^C\\n--- thesvc.default.svc.cluster.local ping statistics ---\\n23 packets transmitted, 0 received, 100% packet loss, time 22522ms\\n\")), mdx(\"p\", null, \"The \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"ping\"), \" results in \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"100% packet loss\"), \", probably, because \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"ping\"), \" is not enable on the application image. However, you can see that the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"thesvc.default.svc.cluster.local\"), \" translating to the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"ClusterIP\"), \" \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"10.15.241.194\"), \".\"), mdx(\"p\", null, \"Let ping the application using the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"FQDN\"), \", from withing the jumppod:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2,6,10}\",\n    \"{2,6,10}\": true\n  }, \"# Using the FQDN\\nsh-4.2# curl thesvc.default.svc.cluster.local/info\\n{\\\"host\\\": \\\"thesvc.default.svc.cluster.local\\\", \\\"version\\\": \\\"0.5.0\\\", \\\"from\\\": \\\"10.12.2.7\\\"}\\n\\n# Using the name of the service `thesvc`\\nsh-4.2# curl thesvc/info\\n{\\\"host\\\": \\\"thesvc\\\", \\\"version\\\": \\\"0.5.0\\\", \\\"from\\\": \\\"10.12.2.7\\\"}\\n\\n# Or\\nsh-4.2# curl http://thesvc/info\\n{\\\"host\\\": \\\"thesvc\\\", \\\"version\\\": \\\"0.5.0\\\", \\\"from\\\": \\\"10.12.2.7\\\"}\\n\")), mdx(\"p\", null, \"Now, let's try to reach the application from within one of the nodes in the cluster\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{1,4,9}\",\n    \"{1,4,9}\": true\n  }, \"Bensooraj@gke-k8s-by-example-default-pool-dec3a359-jsgl ~ $ curl thesvc.default.svc.cluster.local/info\\n# curl: (6) Couldn't resolve host 'thesvc.default.svc.cluster.local'\\n\\nBensooraj@gke-k8s-by-example-default-pool-dec3a359-jsgl ~ $ curl thesvc/info\\n# curl: (6) Couldn't resolve host 'thesvc'\\nBensooraj@gke-k8s-by-example-default-pool-dec3a359-jsgl ~ $ curl http://thesvc/info\\n# curl: (6) Couldn't resolve host 'thesvc'\\n\\nBensooraj@gke-k8s-by-example-default-pool-dec3a359-jsgl ~ $ curl 10.15.241.194/info\\n# {\\\"host\\\": \\\"10.15.241.194\\\", \\\"version\\\": \\\"0.5.0\\\", \\\"from\\\": \\\"10.160.0.18\\\"}\\n\")), mdx(\"p\", null, \"The \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"FQDN\"), \" \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"thesvc.default.svc.cluster.local\"), \" works only from within another \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"pod\"), \" in the same \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"namespace\"), \", unlike the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"ClusterIP\"), \".\"), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"To access a service that is deployed in a different namespace than the one you\\u2019re accessing it from, use a \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"FQDN\"), \" in the form \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"$SVC.$NAMESPACE.svc.cluster.local\"), \".\")), mdx(\"p\", null, \"Let's attempt connecting to a service running in a different namespace\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2,6,14,17,28,32}\",\n    \"{2,6,14,17,28,32}\": true\n  }, \"# Create a new namespace `other`\\n$ kubectl apply -f service-discovery/other-ns.yaml\\nnamespace/other created\\n\\n# Let's list the namespaces\\n$ kubectl get namespaces\\nNAME          STATUS   AGE\\ndefault       Active   3h\\nkube-public   Active   3h\\nkube-system   Active   3h\\nother         Active   7s\\n\\n# Create a ReplicationController in the namespace `other`\\n$ kubectl apply -f service-discovery/other-rc.yaml\\n\\n# List all pods across all namespaces\\n$ kubectl get pods --all-namespaces\\nNAMESPACE     NAME                                                       READY   STATUS    RESTARTS   AGE\\ndefault       jumppod                                                    1/1     Running   0          42m\\ndefault       rcsise-mgdc8                                               1/1     Running   0          1h\\ndefault       rcsise-rwqxt                                               1/1     Running   0          1h\\n.\\n.\\n.\\nother         other-rc-stk98                                             1/1     Running   0          4m\\n\\n# Create the service in the namespace `other`\\n$ kubectl apply -f service-discovery/other-svc.yaml\\nservice/other-sise-service created\\n\\n# List all services across all namespaces\\n$ kubectl get svc --all-namespaces\\nNAMESPACE     NAME                   TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)         AGE\\ndefault       kubernetes             ClusterIP   10.15.240.1     <none>        443/TCP         4h\\ndefault       thesvc                 ClusterIP   10.15.241.194   <none>        80/TCP          1h\\n.\\n.\\n.\\nother         other-sise-service     ClusterIP   10.15.245.253   <none>        80/TCP          3s\\n\")), mdx(\"p\", null, \"Get inside the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"jumppod\"), \" and access the service running in the namespace \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"other\"), \":\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{1,4,8}\",\n    \"{1,4,8}\": true\n  }, \"$ kubectl exec -it jumppod sh\\n\\n# Ping using the FQDN\\nsh-4.2# curl other-sise-service.other.svc.cluster.local/info\\n{\\\"host\\\": \\\"other-sise-service.other.svc.cluster.local\\\", \\\"version\\\": \\\"0.5.0\\\", \\\"from\\\": \\\"10.12.2.7\\\"}\\n\\n# And the shorter version as well\\nsh-4.2# curl other-sise-service.other/info\\n{\\\"host\\\": \\\"other-sise-service.other\\\", \\\"version\\\": \\\"0.5.0\\\", \\\"from\\\": \\\"10.12.2.7\\\"}\\n\")), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"Summing up, DNS-based service discovery provides a flexible and generic way to connect to services across the cluster.\")), mdx(\"p\", null, \"Clean up time!\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2,5,9,12,15}\",\n    \"{2,5,9,12,15}\": true\n  }, \"# Bring down the resources in the namespace `other`\\n$ kubectl --namespace=other delete svc other-sise-service\\nservice \\\"other-sise-service\\\" deleted\\n\\n$ kubectl --namespace=other delete rc other-rc\\nreplicationcontroller \\\"other-rc\\\" deleted\\n\\n# And in the namespace `default`\\n$ kubectl delete svc thesvc\\nservice \\\"thesvc\\\" deleted\\n\\n$ kubectl delete rc rcsise\\nreplicationcontroller \\\"rcsise\\\" deleted\\n\\n$ kubectl delete pod jumppod\\npod \\\"jumppod\\\" deleted\\n\")), mdx(\"p\", null, \"[\", mdx(\"sub\", null, mdx(\"sup\", null, mdx(\"a\", {\n    href: \"#top-contents\"\n  }, \"GO TO TOP\"))), \"]\"), mdx(\"h3\", null, \"Port Forward \", mdx(\"a\", {\n    id: \"port-forward\"\n  })), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"In the context of developing apps on Kubernetes it is often useful to quickly access a service from your local environment without exposing it using, for example, a load balancer or an ingress resource. In this case you can use \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://kubernetes.io/docs/tasks/access-application-cluster/port-forward-access-application-cluster/\"\n  }, \"port forwarding\"), \".\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2,7,12}\",\n    \"{2,7,12}\": true\n  }, \"# Created a Deployment and a corresponding Service using port-forward/port-forward-1.yaml\\n$ kubectl create -f port-forward/port-forward-1.yaml\\ndeployment.apps/sise-deploy created\\nservice/simpleservice created\\n\\n# List the deployment\\n$ kubectl get deployment -o wide\\nNAME          DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES                            SELECTOR\\nsise-deploy   1         1         1            1           1m    sise         mhausenblas/simpleservice:0.5.0   app=sise\\n\\n# And the service\\n$ kubectl get service -o wide\\nNAME            TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE   SELECTOR\\nkubernetes      ClusterIP   10.15.240.1    <none>        443/TCP   13h   <none>\\nsimpleservice   ClusterIP   10.15.244.55   <none>        80/TCP    1m    app=sise\\n\")), mdx(\"p\", null, \"The application running in GKE is either accessible from the pods or from any node of the cluster. We want to access the service from our local machine as well for development.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2,7,10}\",\n    \"{2,7,10}\": true\n  }, \"# Fetch the pod IP\\n$ kubectl describe pods sise-deploy-56955c466c-dz99x | grep IP\\nIP:                 10.12.2.9\\n\\n\\n# From the local machine, let's curl the pod's IP\\n$ curl 10.12.2.9:9876/info\\n\\n# Or the ClusteIP created by the service\\n$ curl 10.15.244.55/info\\n\")), mdx(\"p\", null, \"They return nothing. Let's do a \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"port-forward\"), \" now.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2,7}\",\n    \"{2,7}\": true\n  }, \"# To access the `simpleservice` service from the local environment on port 8080\\n$ kubectl port-forward service/simpleservice 8080:80\\nForwarding from 127.0.0.1:8080 -> 9876\\nForwarding from [::1]:8080 -> 9876\\n\\n# Curl localhost:8080\\n$ curl localhost:8080/info\\n{\\\"host\\\": \\\"localhost:8080\\\", \\\"version\\\": \\\"0.5.0\\\", \\\"from\\\": \\\"127.0.0.1\\\"}\\n\\n# Perfecto!\\n\")), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Remember that port forwarding is not meant for production traffic but for development and experimentation.\"))), mdx(\"p\", null, \"Clean up!\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{1}\",\n    \"{1}\": true\n  }, \"$ kubectl delete -f port-forward/port-forward-1.yaml\\ndeployment.apps \\\"sise-deploy\\\" deleted\\nservice \\\"simpleservice\\\" deleted\\n\")), mdx(\"p\", null, \"[\", mdx(\"sub\", null, mdx(\"sup\", null, mdx(\"a\", {\n    href: \"#top-contents\"\n  }, \"GO TO TOP\"))), \"]\"), mdx(\"h3\", null, \"Health Checks \", mdx(\"a\", {\n    id: \"health-checks\"\n  })), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"In order to verify if a container in a pod is healthy and ready to serve traffic, Kubernetes provides for a range of health checking mechanisms. Health checks, or probes as they are called in Kubernetes, are carried out by the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"kubelet\"), \" to determine when to restart a container (for \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"livenessProbe\"), \") and used by services and deployments to determine if a pod should receive traffic (for \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"readinessProbe\"), \").\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2,6,11}\",\n    \"{2,6,11}\": true\n  }, \"# Pod which exposes /health for liveness health check. Kubernetes will start checking the /health endpoint, after initially waiting 2 seconds, every 5 seconds.\\n$ kubectl apply -f health-checks/liveness-pod.yaml\\npod/readiness-pod created\\n\\n# List the pod\\n$ kubectl get pods -o wide\\nNAME            READY   STATUS    RESTARTS   AGE   IP          NODE                                            NOMINATED NODE\\nreadiness-pod   1/1     Running   0          1m    10.12.1.6   gke-k8s-by-example-default-pool-85e67e86-2xlh   <none>\\n\\n# Describe the pod\\n$ kubectl describe pods readiness-pod\\n\")), mdx(\"p\", null, \"Relevant excerpt from \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"kubectl describe pods readiness-pod\"), \":\"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"960px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"29.583333333333332%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAABYlAAAWJQFJUiTwAAAA60lEQVQY052QzW6DMBCE/f7P1WMvqZRQFQGCtLaxIdgYMISfqVmpKM2hh470aeZg766GNU2DXUIIOOcob9tGzPOMZVmwrivxk/8Si+MY4ziCc44kSYg0TZHnObTSUErRMiElpJDQWtP7R7z35PsR7HKJMIfNp9MbDaqqGjJ8VmFY27YwxsBYi6YxR7YByk/s17MoumDoHErB0Qe/Tx6THzCNHv8Re3k9I+EW77nC183jqjt8Vj1RhHygHPLSIRMWlR1+df0IO0cfyIrQX1aAlxWkrsGlJi/1DUKFCgKqNuiGCf04Y7ovx8BnfQM0ncxTfsa/UwAAAABJRU5ErkJggg==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Health 1\",\n    \"title\": \"Health 1\",\n    \"src\": \"/static/aa16287ce67e3ab08f199118cdf7150a/7d769/health-1.png\",\n    \"srcSet\": [\"/static/aa16287ce67e3ab08f199118cdf7150a/5243c/health-1.png 240w\", \"/static/aa16287ce67e3ab08f199118cdf7150a/ab158/health-1.png 480w\", \"/static/aa16287ce67e3ab08f199118cdf7150a/7d769/health-1.png 960w\", \"/static/aa16287ce67e3ab08f199118cdf7150a/87339/health-1.png 1440w\", \"/static/aa16287ce67e3ab08f199118cdf7150a/88b03/health-1.png 1920w\", \"/static/aa16287ce67e3ab08f199118cdf7150a/916cf/health-1.png 2238w\"],\n    \"sizes\": \"(max-width: 960px) 100vw, 960px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n    \")), mdx(\"p\", null, \"Let's launch a bad/unhealthy pod now, that has a container that randomly (in the time range 1 to 4 sec) does not return a 200 code.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2,6,24}\",\n    \"{2,6,24}\": true\n  }, \"# Launch the bad pod\\n$ kubectl apply -f health-checks/bad-pod.yaml\\npod/bad-pod created\\n\\n# List out the pods; look at the number of restarts!\\n$ kubectl get pods -o wide\\nNAME            READY   STATUS    RESTARTS   AGE   IP          NODE                                            NOMINATED NODE\\nbad-pod         1/1     Running   4          4m    10.12.0.5   gke-k8s-by-example-default-pool-85e67e86-qbpv   <none>\\nreadiness-pod   1/1     Running   0          17m   10.12.1.6   gke-k8s-by-example-default-pool-85e67e86-2xlh   <none>\\n\\n# Logging out the bad-pod\\n$ kubectl logs -f bad-pod\\n# 2019-03-18T06:38:49 INFO This is simple service in version v0.5.0 listening on port 9876 [at line 142]\\n# 2019-03-18T06:38:52 INFO /health serving from 10.12.0.5:9876 has been invoked from 10.12.0.1 [at line 79]\\n# 2019-03-18T06:38:55 INFO 200 GET /health (10.12.0.1) 3277.99ms [at line 1946]\\n# 2019-03-18T06:38:57 INFO /health serving from 10.12.0.5:9876 has been invoked from 10.12.0.1 [at line 79]\\n# 2019-03-18T06:39:00 INFO 200 GET /health (10.12.0.1) 3540.73ms [at line 1946]\\n# 2019-03-18T06:39:02 INFO /health serving from 10.12.0.5:9876 has been invoked from 10.12.0.1 [at line 79]\\n# 2019-03-18T06:39:06 INFO 200 GET /health (10.12.0.1) 3778.49ms [at line 1946]\\n# ..\\n# ..\\n\\n# Print out the events as well\\n$ kubectl describe pods bad-pod\\n\")), mdx(\"p\", null, \"Relevant excerpt from printing out the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"bad-pod\"), \" events:\"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"960px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"21.666666666666668%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAw0lEQVQY002P6w6DIAyFff/X03m/4YaiomIMov45o02WjORLy6G0PYGUEkRd15jnGXScOzGOo79rGGOYbduwLAvWdcU0TVBKoe97ZhgG/nscB4J/kYq01hy7roMQAkVR+Fzw0LZt0UmFpFFI2xGVXFESnwX5W2M2FkFVVSCapkFZlgjDEFmWIYoipGmK1ytCkefsII4TCN+UG/uBv+2Jfd+ZgKzRhmTpui6Y3eA8Lay1eJ6Hue+boXeKpFHunGN++uX5AslhKq9ypqV7AAAAAElFTkSuQmCC')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Health 2\",\n    \"title\": \"Health 2\",\n    \"src\": \"/static/42c81cf870da93bdfd6642971f80cf27/7d769/health-2.png\",\n    \"srcSet\": [\"/static/42c81cf870da93bdfd6642971f80cf27/5243c/health-2.png 240w\", \"/static/42c81cf870da93bdfd6642971f80cf27/ab158/health-2.png 480w\", \"/static/42c81cf870da93bdfd6642971f80cf27/7d769/health-2.png 960w\", \"/static/42c81cf870da93bdfd6642971f80cf27/87339/health-2.png 1440w\", \"/static/42c81cf870da93bdfd6642971f80cf27/88b03/health-2.png 1920w\", \"/static/42c81cf870da93bdfd6642971f80cf27/8355f/health-2.png 2560w\"],\n    \"sizes\": \"(max-width: 960px) 100vw, 960px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n    \")), mdx(\"p\", null, \"Let\\u2019s create a pod with a \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"readinessProbe\"), \" that signals when the container is ready to serve traffica and kicks in after 10 seconds:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2,6,13}\",\n    \"{2,6,13}\": true\n  }, \"# Create the pod\\n$ kubectl apply -f health-checks/readiness-pod.yaml\\npod/readiness-pod-1 created\\n\\n# List the pods now\\n$ kubectl get pods -o wide\\nNAME              READY   STATUS             RESTARTS   AGE   IP          NODE                                            NOMINATED NODE\\nbad-pod           0/1     CrashLoopBackOff   11         27m   10.12.0.5   gke-k8s-by-example-default-pool-85e67e86-qbpv   <none>\\nreadiness-pod     1/1     Running            0          40m   10.12.1.6   gke-k8s-by-example-default-pool-85e67e86-2xlh   <none>\\nreadiness-pod-1   1/1     Running            0          1m    10.12.1.7   gke-k8s-by-example-default-pool-85e67e86-2xlh   <none>\\n\\n# Describe the pods events\\n$ kubectl describe pods readiness-pod-1\\n\")), mdx(\"p\", null, \"Relevant excerpt from printing out the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"readiness-pod-1\"), \" events:\"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"960px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"24.166666666666664%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAtklEQVQY032QbQvDIAyE/f//cAwZpVZLrXTVqn2/NRZH+2ETHk5CSO7ClFKI4wjnHPq+xzAMCe89QgiIMSL4U8ej79fb9z0pq0QJ7yyUFOCcQ0oJIQTqukbbttBao2l0UmNMWmytTWQTy7J8h7IHL/AUBs/iHEBOyOE0TbfNpMS2bVjX9ca1hxVlhVepoM07Dckx6U+biXmeE7n2N7I6IlLsWsnksOu6m1JMgm5KN6TBV8eZXPsARiqC97bU9UYAAAAASUVORK5CYII=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Health 3\",\n    \"title\": \"Health 3\",\n    \"src\": \"/static/7768db289f3be6d6cd7cfc73ac370c17/7d769/health-3.png\",\n    \"srcSet\": [\"/static/7768db289f3be6d6cd7cfc73ac370c17/5243c/health-3.png 240w\", \"/static/7768db289f3be6d6cd7cfc73ac370c17/ab158/health-3.png 480w\", \"/static/7768db289f3be6d6cd7cfc73ac370c17/7d769/health-3.png 960w\", \"/static/7768db289f3be6d6cd7cfc73ac370c17/87339/health-3.png 1440w\", \"/static/7768db289f3be6d6cd7cfc73ac370c17/88b03/health-3.png 1920w\", \"/static/7768db289f3be6d6cd7cfc73ac370c17/256cb/health-3.png 2558w\"],\n    \"sizes\": \"(max-width: 960px) 100vw, 960px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n    \")), mdx(\"p\", null, \"Clean up time:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{1}\",\n    \"{1}\": true\n  }, \"$ kubectl delete pods --all\\npod \\\"bad-pod\\\" deleted\\npod \\\"readiness-pod\\\" deleted\\npod \\\"readiness-pod-1\\\" deleted\\n\")), mdx(\"p\", null, \"I just realised; I messed up the pod names. Sorry!\"), mdx(\"p\", null, \"[\", mdx(\"sub\", null, mdx(\"sup\", null, mdx(\"a\", {\n    href: \"#top-contents\"\n  }, \"GO TO TOP\"))), \"]\"), mdx(\"h3\", null, \"Environment Variables \", mdx(\"a\", {\n    id: \"environment-variables\"\n  })), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"You can set environment variables for containers running in a pod and in addition, Kubernetes exposes certain runtime infos via environment variables automatically.\")), mdx(\"p\", null, \"Launch a pod with the environment variable \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"SIMPLE_SERVICE_VERSION\"), \" and value \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"\\\"1.0\\\"\"), \":\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2,6,11,15,18}\",\n    \"{2,6,11,15,18}\": true\n  }, \"# Use environment-variables/env-pod.yaml\\n$ kubectl apply -f environment-variables/env-pod.yaml\\npod/envs created\\n\\n# List the pods\\n$ kubectl get pods -o wide\\nNAME   READY   STATUS    RESTARTS   AGE   IP          NODE                                            NOMINATED NODE\\nenvs   1/1     Running   0          2m    10.12.2.6   gke-k8s-by-example-default-pool-6c270685-0hd5   <none>\\n\\n# Grab the IP address:\\n$ kubectl describe pod envs | grep IP\\nIP:                 10.12.2.6\\n\\n# Curl the pod IP from inside the cluster\\n[CLUSTER] $ curl 10.12.2.6:9876/info && echo\\n{\\\"host\\\": \\\"10.12.2.6:9876\\\", \\\"version\\\": \\\"1.0\\\", \\\"from\\\": \\\"10.12.2.1\\\"}\\n\\n[CLUSTER] $ curl 10.12.2.6:9876/env && echo\\n{\\\"version\\\": \\\"1.0\\\", \\\"env\\\": \\\"{'LANG': 'C.UTF-8', 'KUBERNETES_PORT_443_TCP_PROTO': 'tcp', 'KUBERNETES_PORT_443_TCP': 'tcp://10.15.240.1:443', 'SIMPLE_SERVICE_VERSION': '1.0', 'PYTHON_PIP_VERSION': '9.0.1', 'KUBERNETES_SERVICE_HOST': '10.15.240.1', 'HOSTNAME': 'envs', 'KUBERNETES_SERVICE_PORT_HTTPS': '443', 'REFRESHED_AT': '2017-04-24T13:50', 'GPG_KEY': 'C01E1CAD5EA2C4F0B8E3571504C367C218ADD4FF', 'KUBERNETES_PORT_443_TCP_ADDR': '10.15.240.1', 'KUBERNETES_PORT': 'tcp://10.15.240.1:443', 'PATH': '/usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'KUBERNETES_PORT_443_TCP_PORT': '443', 'HOME': '/root', 'KUBERNETES_SERVICE_PORT': '443', 'PYTHON_VERSION': '2.7.13'}\\\"}\\n\")), mdx(\"p\", null, \"Or, \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"exec\"), \" into the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"envs\"), \" pod and printout the variables:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{1}\",\n    \"{1}\": true\n  }, \"$ kubectl exec envs -- sh -c 'env'\\nKUBERNETES_SERVICE_PORT=443\\nKUBERNETES_PORT=tcp://10.15.240.1:443\\nHOSTNAME=envs\\nPYTHON_PIP_VERSION=9.0.1\\nHOME=/root\\nGPG_KEY=C01E1CAD5EA2C4F0B8E3571504C367C218ADD4FF\\nSIMPLE_SERVICE_VERSION=1.0\\nKUBERNETES_PORT_443_TCP_ADDR=10.15.240.1\\nPATH=/usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\\nKUBERNETES_PORT_443_TCP_PORT=443\\nKUBERNETES_PORT_443_TCP_PROTO=tcp\\nLANG=C.UTF-8\\nPYTHON_VERSION=2.7.13\\nKUBERNETES_SERVICE_PORT_HTTPS=443\\nKUBERNETES_PORT_443_TCP=tcp://10.15.240.1:443\\nKUBERNETES_SERVICE_HOST=10.15.240.1\\nPWD=/usr/src/app\\nREFRESHED_AT=2017-04-24T13:50\\n\")), mdx(\"p\", null, \"Clean up time:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{1}\",\n    \"{1}\": true\n  }, \"$ kubectl delete pods --all\\npod \\\"envs\\\" deleted\\n\")), mdx(\"p\", null, \"[\", mdx(\"sub\", null, mdx(\"sup\", null, mdx(\"a\", {\n    href: \"#top-contents\"\n  }, \"GO TO TOP\"))), \"]\"), mdx(\"h3\", null, \"Namespaces \", mdx(\"a\", {\n    id: \"namespaces\"\n  })), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Namespaces\"), \" provide for a scope of Kubernetes resource, carving up your cluster in smaller units. You can think of it as a workspace you\\u2019re sharing with other users.\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2,6,14}\",\n    \"{2,6,14}\": true\n  }, \"# Create a namespace named ben-test-namespace\\n$ kubectl apply -f namespaces/ns.yaml\\nnamespace/ben-test-namespace created\\n\\n# List all the namespaces\\n$ kubectl get ns\\nNAME                 STATUS   AGE\\nben-test-namespace   Active   14s\\ndefault              Active   4h\\nkube-public          Active   4h\\nkube-system          Active   4h\\n\\n# Know more about the namespace\\n$ kubectl describe ns ben-test-namespace\\nName:         ben-test-namespace\\nLabels:       <none>\\nAnnotations:  kubectl.kubernetes.io/last-applied-configuration:\\n                {\\\"apiVersion\\\":\\\"v1\\\",\\\"kind\\\":\\\"Namespace\\\",\\\"metadata\\\":{\\\"annotations\\\":{},\\\"name\\\":\\\"ben-test-namespace\\\"}}\\nStatus:       Active\\n\\nResource Quotas\\n Name:                       gke-resource-quotas\\n Resource                    Used  Hard\\n --------                    ---   ---\\n count/ingresses.extensions  0     1G\\n count/jobs.batch            0     1G\\n pods                        0     1G\\n services                    0     1G\\n\\nNo resource limits.\\n\")), mdx(\"h5\", null, \"Launching k8s resources/objects in the newly created namespaces\"), mdx(\"p\", null, \"There are two ways you can accomplishe this. First, using kubectl's \\\"namespace' flag:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{1}\",\n    \"{1}\": true\n  }, \"$ kubectl --namespace=ben-test-namespace apply -f namespaces/pod.yaml\\npod/pod-in-ben-test-namespace created\\n\")), mdx(\"p\", null, \"Second, by mentioning the namespace in the pod yaml file, under \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"metadata.namespace\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-yaml\",\n    \"metastring\": \"{5}\",\n    \"{5}\": true\n  }, \"apiVersion: v1\\nkind: Pod\\nmetadata:\\n  name: pod-in-ben-test-namespace\\n  namespace: ben-test-namespace\\nspec:\\n\")), mdx(\"p\", null, \"Clean up time!\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2,6}\",\n    \"{2,6}\": true\n  }, \"# Pod in the newly created namespace\\n$ kubectl --namespace=ben-test-namespace delete pod pod-in-ben-test-namespace\\npod \\\"pod-in-ben-test-namespace\\\" deleted\\n\\n# Then the newly created namespace\\n$ kubectl delete namespaces ben-test-namespace\\nnamespace \\\"ben-test-namespace\\\" deleted\\n\")), mdx(\"p\", null, \"[\", mdx(\"sub\", null, mdx(\"sup\", null, mdx(\"a\", {\n    href: \"#top-contents\"\n  }, \"GO TO TOP\"))), \"]\"), mdx(\"h3\", null, \"Volumes \", mdx(\"a\", {\n    id: \"volumes\"\n  })), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"A Kubernetes volume is essentially a directory accessible to all containers running in a pod. In contrast to the container-local filesystem, the data in volumes is preserved across container restarts.\")), mdx(\"p\", null, \"The medium backing a volume and its contents are determined by the volume type:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"node-local types such as \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"emptyDir\"), \" or \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"hostPath\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"file-sharing types such as \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"nfs\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"cloud provider-specific types like \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"awsElasticBlockStore\"), \", \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"azureDisk\"), \", or \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"gcePersistentDisk\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"distributed file system types, for example \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"glusterfs\"), \" or \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"cephfs\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"special-purpose types like \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"secret\"), \", \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"gitRepo\"))), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2,6,11}\",\n    \"{2,6,11}\": true\n  }, \"# Create the pod with the two containers\\n$ kubectl apply -f volumes/pod.yaml\\npod/sharevol created\\n\\n# List the pods\\n$ kubectl get pods -o wide\\nNAME       READY   STATUS    RESTARTS   AGE   IP          NODE                                            NOMINATED NODE\\nsharevol   2/2     Running   0          48s   10.12.1.8   gke-k8s-by-example-default-pool-200a36e7-c33r   <none>\\n\\n# Describe the pod (showing only relevant excerpts)\\n$ kubectl describe pod sharevol\\nName:               sharevol\\nNamespace:          default\\nIP:                 10.12.1.8\\nContainers:\\n  c1:\\n    Image:         centos:7\\n    Mounts:\\n      /tmp/xchange from xchange (rw)\\n  c2:\\n    Image:         centos:7\\n    Mounts:\\n      /temp/data from xchange (rw)\\n.\\n.\\nVolumes:\\n  xchange:\\n    Type:    EmptyDir (a temporary directory that shares a pod's lifetime)\\n    Medium:\\n\")), mdx(\"p\", null, \"Let's get inside the containers \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"c1\"), \" and \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"c2\"), \" and play around. Inside container \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"c1\"), \":\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2}\",\n    \"{2}\": true\n  }, \"# Exec into the first container c1\\n$ kubectl exec -it sharevol -c c1 -- bash\\n[root@sharevol /]#\\n[root@sharevol /]# mount | grep xchange\\n/dev/sda1 on /tmp/xchange type ext4 (rw,relatime,commit=30,data=ordered)\\n# Create a\\n[root@sharevol /]# cd /tmp/xchange/\\n[root@sharevol xchange]# echo \\\"Hannah! I love you babe :)\\\" > love.txt\\n[root@sharevol xchange]# cat love.txt\\nHannah! I love you babe :)\\n\")), mdx(\"p\", null, \"Now, let's checkout the second container \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"c2\"), \":\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{1}\",\n    \"{1}\": true\n  }, \"$ kubectl exec -it sharevol -c c2 -- bash\\n[root@sharevol /]# cd /temp/data/\\n# Guess what!? The love.txt file which we created\\n# in the first container is available here\\n[root@sharevol data]# ls\\nlove.txt\\n# Let's peek into the content too\\n[root@sharevol data]# cat love.txt\\nHannah! I love you babe :)\\n\")), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"Note that in each container you need to decide where to mount the volume and that for \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"emptyDir\"), \" you currently \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"can not\"), \" specify resource consumption limits.\")), mdx(\"p\", null, \"Clean up time:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{1}\",\n    \"{1}\": true\n  }, \"$ kubectl delete pods --all\\npod \\\"sharevol\\\" deleted\\n\")), mdx(\"p\", null, \"[\", mdx(\"sub\", null, mdx(\"sup\", null, mdx(\"a\", {\n    href: \"#top-contents\"\n  }, \"GO TO TOP\"))), \"]\"), mdx(\"h3\", null, \"Secrets \", mdx(\"a\", {\n    id: \"secrets\"\n  })), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"Secrets provide you with a mechanism to use information such as database passwords or an API keys in a safe (non-plain text) and reliable way with the following properties:\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Secrets are namespaced objects, that is, exist in the context of a \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"namespace\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"You can access them via a volume or an environment variable from a container running in a pod\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"The secret data on nodes is stored in \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"tmpfs\"), \" volumes\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"A per-secret size limit of \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"1MB\"), \" exists\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"The API server stores secrets as plaintext in etcd\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2,5,9}\",\n    \"{2,5,9}\": true\n  }, \"# Dump some random text to the file secrets/api-key.txt\\n$ echo -n \\\"k2hl1bflkh4lk23b41lkdlk23b4l341234\\\" > secrets/api-key.txt\\n\\n# Create a new secret named apikey using the file secrets/api-key.txt\\n$ kubectl create secret generic apikey --from-file=secrets/api-key.txt\\nsecret/apikey created\\n\\n# Describe the secret we just created\\n$ kubectl describe secrets apikey\\nName:         apikey\\nNamespace:    default\\nLabels:       <none>\\nAnnotations:  <none>\\n\\nType:  Opaque\\n\\nData\\n====\\napi-key.txt:  34 bytes\\n\")), mdx(\"p\", null, \"Let's now use the secret that we just created\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2,6,11,14,18}\",\n    \"{2,6,11,14,18}\": true\n  }, \"# Create a pod which uses the secret apikey\\n$ kubectl apply -f secrets/pod.yaml\\npod/pod-with-secret created\\n\\n# List the pod\\n$ kubectl get pods -o wide\\nNAME              READY   STATUS    RESTARTS   AGE   IP          NODE                                            NOMINATED NODE\\npod-with-secret   1/1     Running   0          4m    10.12.1.6   gke-k8s-by-example-default-pool-635ddecf-1xsh   <none>\\n\\n# Get inside the pod\\n$ kubectl exec -it pod-with-secret -- bash\\n\\n# You can see secret file api-key.txt at \\\"tmp/apikey/\\\"\\n[root@pod-with-secret /]# ls tmp/apikey/\\napi-key.txt\\n\\n# Let's checkout out its content\\n[root@pod-with-secret /]# cat tmp/apikey/api-key.txt\\nk2hl1bflkh4lk23b41lkdlk23b4l341234\\n\")), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"Note that for service accounts Kubernetes automatically creates secrets containing credentials for accessing the API and modifies your pods to use this type of secret.\")), mdx(\"p\", null, \"Clean up time:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{1}\",\n    \"{1}\": true\n  }, \"$ kubectl delete pods --all\\npod \\\"pod-with-secret\\\" deleted\\n\")), mdx(\"p\", null, \"[\", mdx(\"sub\", null, mdx(\"sup\", null, mdx(\"a\", {\n    href: \"#top-contents\"\n  }, \"GO TO TOP\"))), \"]\"), mdx(\"h3\", null, \"Logging \", mdx(\"a\", {\n    id: \"logging\"\n  })), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"Logging is one option to understand what is going on inside your applications and the cluster at large. Basic logging in Kubernetes makes the output a container produces available, which is a good use case for debugging.\")), mdx(\"p\", null, \"Create a pod \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"logme\"), \" that writes to \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"stdout\"), \" and \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"stderr\"), \":\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2,6,14}\",\n    \"{2,6,14}\": true\n  }, \"# Create the pod using logging/pod.yaml\\n$ kubectl apply -f logging/pod.yaml\\npod/logme created\\n\\n# View the five most recent log lines of the gen container in the logme pod\\n$ kubectl logs --tail=5 logme -c gen\\nSat Mar 23 21:55:51 UTC 2019\\nSat Mar 23 21:55:52 UTC 2019\\nSat Mar 23 21:55:52 UTC 2019\\nSat Mar 23 21:55:53 UTC 2019\\nSat Mar 23 21:55:53 UTC 2019\\n\\n# Stream the log of the gen container in the logme pod\\n$ kubectl logs -f --since=5s logme -c gen\\nSat Mar 23 21:57:28 UTC 2019\\nSat Mar 23 21:57:28 UTC 2019\\nSat Mar 23 21:57:29 UTC 2019\\nSat Mar 23 21:57:29 UTC 2019\\n.......\\n......\\n.....\\n....\\n...\\n..\\n.\\n\")), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"..if you wouldn\\u2019t have specified --since=10s in the above command, you would have gotten all log lines from the start of the container. ...You can also view logs of pods that have already completed their lifecycle.\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2,6}\",\n    \"{2,6}\": true\n  }, \"# Create a new pod which counts down from 9 to 1\\n$ kubectl apply -f logging/oneshot.yaml\\npod/oneshot created\\n\\n# Let's log it out\\n$ kubectl logs -p oneshot -c gen\\n9\\n8\\n7\\n6\\n5\\n4\\n3\\n2\\n1\\n\")), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"Using the -p option you can print the logs for previous instances of the container in a pod\")), mdx(\"p\", null, \"Clean up time:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{1}\",\n    \"{1}\": true\n  }, \"$ kubectl delete pods --all\\npod \\\"logme\\\" deleted\\npod \\\"oneshot\\\" deleted\\n\")), mdx(\"p\", null, \"[\", mdx(\"sub\", null, mdx(\"sup\", null, mdx(\"a\", {\n    href: \"#top-contents\"\n  }, \"GO TO TOP\"))), \"]\"), mdx(\"h3\", null, \"Jobs \", mdx(\"a\", {\n    id: \"jobs\"\n  })), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"A job in Kubernetes is a supervisor for pods carrying out batch processes, that is, a process that runs for a certain time to completion, for example a calculation or a backup operation.\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2,6,11,16,49}\",\n    \"{2,6,11,16,49}\": true\n  }, \"# Create a job called countdown that supervises a pod counting from 9 down to 1:\\n$ kubectl apply -f jobs/job.yaml\\njob.batch/countdown created\\n\\n# List the job\\n$ kubectl get jobs -o wide\\nNAME        DESIRED   SUCCESSFUL   AGE   CONTAINERS   IMAGES     SELECTOR\\ncountdown   1         1            31s   counter      centos:7   controller-uid=04f4458c-4dbc-11e9-a1d6-42010aa00ff8\\n\\n# List the pods as well\\n$ kubectl get pods -o wide\\nNAME              READY   STATUS      RESTARTS   AGE   IP          NODE                                            NOMINATED NODE\\ncountdown-td4vz   0/1     Completed   0          2m    10.12.1.9   gke-k8s-by-example-default-pool-635ddecf-1xsh   <none>\\n\\n# Decribe a job\\n$ kubectl describe jobs countdown\\nName:           countdown\\nNamespace:      default\\nSelector:       controller-uid=04f4458c-4dbc-11e9-a1d6-42010aa00ff8\\nLabels:         controller-uid=04f4458c-4dbc-11e9-a1d6-42010aa00ff8\\n                job-name=countdown\\nParallelism:    1\\nCompletions:    1\\nStart Time:     Sun, 24 Mar 2019 04:05:54 +0530\\nCompleted At:   Sun, 24 Mar 2019 04:05:55 +0530\\nDuration:       1s\\nPods Statuses:  0 Running / 1 Succeeded / 0 Failed\\nPod Template:\\n  Labels:  controller-uid=04f4458c-4dbc-11e9-a1d6-42010aa00ff8\\n           job-name=countdown\\n  Containers:\\n   counter:\\n    Image:      centos:7\\n    Port:       <none>\\n    Host Port:  <none>\\n    Command:\\n      bin/bash\\n      -c\\n      for i in 9 8 7 6 5 4 3 2 1 ; do echo $i ; done\\n    Environment:  <none>\\n    Mounts:       <none>\\n  Volumes:        <none>\\nEvents:\\n  Type    Reason            Age    From            Message\\n  ----    ------            ----   ----            -------\\n  Normal  SuccessfulCreate  3m55s  job-controller  Created pod: countdown-td4vz\\n\\n# Checkout the output of the logs as well\\n$ kubectl logs countdown-td4vz\\n9\\n8\\n7\\n6\\n5\\n4\\n3\\n2\\n1\\n\")), mdx(\"p\", null, \"Clean up time:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{1}\",\n    \"{1}\": true\n  }, \"$ kubectl delete jobs countdown\\njob.batch \\\"countdown\\\" deleted\\n\")), mdx(\"p\", null, \"[\", mdx(\"sub\", null, mdx(\"sup\", null, mdx(\"a\", {\n    href: \"#top-contents\"\n  }, \"GO TO TOP\"))), \"]\"), mdx(\"h3\", null, \"StatefulSet \", mdx(\"a\", {\n    id: \"statefulset\"\n  })), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"If you have a stateless app you want to use a \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Deployment\"), \". However, for a stateful app you might want to use a \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"StatefulSet\"), \". Unlike a \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Deployment\"), \", the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"StatefulSet\"), \" provides certain guarantees about the identity of the pods it is managing (that is, predictable names) and about the startup order. Two more things that are different compared to a \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Deployment\"), \": for network communication you need to create a \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"headless services\"), \" and for persistency the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"StatefulSet\"), \" manages a \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"persistent volume\"), \" per pod.\")), mdx(\"p\", null, \"We will be using an \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://blog.openshift.com/kubernetes-statefulset-in-action/\"\n  }, \"educational Kubernetes-native NoSQL datastore\"), \" called \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"mehdb\"), \" for this exercise.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2,7,12}\",\n    \"{2,7,12}\": true\n  }, \"# Verify if the yaml file is fine\\n$ kubectl apply -f statefulset/mehdb-sts-svc.yaml --dry-run=true\\nstatefulset.apps/mehdb created (dry run)\\nservice/mehdb created (dry run)\\n\\n# Create the statefulset along with the persistent volume and the headless service\\n$ kubectl apply -f statefulset/mehdb-sts-svc.yaml\\nstatefulset.apps/mehdb created\\nservice/mehdb created\\n\\n# You can see how the pods are created in order\\n$ kubectl get pods -o wide -w\\nNAME      READY   STATUS              RESTARTS   AGE   IP       NODE                                            NOMINATED NODE\\nmehdb-0   0/1     ContainerCreating   0          24s   <none>   gke-k8s-by-example-default-pool-635ddecf-1xsh   <none>\\nmehdb-0   0/1   Running   0     43s   10.12.1.10   gke-k8s-by-example-default-pool-635ddecf-1xsh   <none>\\nmehdb-0   1/1   Running   0     86s   10.12.1.10   gke-k8s-by-example-default-pool-635ddecf-1xsh   <none>\\nmehdb-1   0/1   Pending   0     0s    <none>   <none>   <none>\\nmehdb-1   0/1   Pending   0     0s    <none>   <none>   <none>\\nmehdb-1   0/1   Pending   0     5s    <none>   <none>   <none>\\nmehdb-1   0/1   Pending   0     5s    <none>   gke-k8s-by-example-default-pool-635ddecf-30n4   <none>\\nmehdb-1   0/1   ContainerCreating   0     5s    <none>   gke-k8s-by-example-default-pool-635ddecf-30n4   <none>\\nmehdb-1   0/1   Running   0     32s   10.12.2.5   gke-k8s-by-example-default-pool-635ddecf-30n4   <none>\\nmehdb-1   1/1   Running   0     56s   10.12.2.5   gke-k8s-by-example-default-pool-635ddecf-30n4   <none>\\n\")), mdx(\"p\", null, \"A summary of all the resources that have been created:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2}\",\n    \"{2}\": true\n  }, \"# Let's checkout all the resources created\\n$ kubectl get sts,po,pvc,svc -o wide\\nNAME                     DESIRED   CURRENT   AGE   CONTAINERS   IMAGES\\nstatefulset.apps/mehdb   2         2         8m    shard        quay.io/mhausenblas/mehdb:0.6\\n\\nNAME          READY   STATUS    RESTARTS   AGE   IP           NODE                                            NOMINATED NODE\\npod/mehdb-0   1/1     Running   0          8m    10.12.1.10   gke-k8s-by-example-default-pool-635ddecf-1xsh   <none>\\npod/mehdb-1   1/1     Running   0          7m    10.12.2.5    gke-k8s-by-example-default-pool-635ddecf-30n4   <none>\\n\\nNAME                                 STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE\\npersistentvolumeclaim/data-mehdb-0   Bound    pvc-8a824c22-4f7e-11e9-9777-42010aa00008   1Gi        RWO            standard       8m\\npersistentvolumeclaim/data-mehdb-1   Bound    pvc-be0d2686-4f7e-11e9-9777-42010aa00008   1Gi        RWO            standard       7m\\n\\nNAME                 TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)    AGE   SELECTOR\\nservice/kubernetes   ClusterIP   10.15.240.1   <none>        443/TCP    2d    <none>\\nservice/mehdb        ClusterIP   None          <none>        9876/TCP   8m    app=mehdb\\n\")), mdx(\"p\", null, \"Let's access the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"StatefulSet\"), \" via a jump pod:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{1,6,14,21,26,32}\",\n    \"{1,6,14,21,26,32}\": true\n  }, \"$ kubectl run -it --rm jumppod --restart=Never --image=quay.io/mhausenblas/jump:0.2 -- sh\\nIf you do not see a command prompt, try pressing enter.\\n~ $\\n\\n# The headless service itself has no cluster IP and has created two endpoints for the pods mehdb-0 and mehdb-1 respectively. The DNS configuration now returns A record entries for the pods\\n~ $ nslookup mehdb\\nnslookup: cannot resolve '(null)': Name does not resolve\\n\\nName:      mehdb\\nAddress 1: 10.12.1.10 mehdb-0.mehdb.default.svc.cluster.local\\nAddress 2: 10.12.2.5 mehdb-1.mehdb.default.svc.cluster.local\\n\\n# Since there is no data in the datastore, /status?level=full should return a 0\\n~ $ curl mehdb:9876/status?level=full\\n0\\n\\n# Let's put some data now\\n~ $ echo \\\"test data\\\" > /tmp/test\\n~ $ cat /tmp/test\\ntest data\\n~ $ curl -sL -XPUT -T /tmp/test mehdb:9876/set/test\\nopen /mehdbdata/test/content: no such file or directory\\n\\n# Unable to set value for the key test. So logging out mehdb-0's activity reveals some\\n# permissions issue. Will debug this later\\n$ kubectl logs mehdb-0 -f\\n2019/03/26 04:21:35 mehdb serving from mehdb-0:9876 using /mehdbdata as the data directory\\n2019/03/26 04:21:35 I am the leading shard, accepting both WRITES and READS\\n2019/03/26 05:09:14 Cannot write key test due to open /mehdbdata/test/content: no such file or directory\\n\\n# Found another issue\\n$ kubectl logs mehdb-1 -f\\n2019/03/26 05:29:48 Checking for new data from leader\\n2019/03/26 05:29:48 Cannot get keys from leader due to Get http://mehdb-0.default:9876/keys: dial tcp: lookup mehdb-0.default on 10.15.240.10:53: no such host\\n\")), mdx(\"p\", null, mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"mehdb-1\"), \" should be querying at \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"mehdb-0.mehdb.default:9876/keys\"), \" instead of at \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"http://mehdb-0.default:9876/keys\"), \".\"), mdx(\"p\", null, \"Clean up time!\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{1,5,15,20}\",\n    \"{1,5,15,20}\": true\n  }, \"$ kubectl delete sts mehdb\\nstatefulset.apps \\\"mehdb\\\" deleted\\n\\n# We are left with the persistent volume and the service\\n$ kubectl get sts,po,pvc,svc -o wide\\nNAME                                 STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE\\npersistentvolumeclaim/data-mehdb-0   Bound    pvc-8a824c22-4f7e-11e9-9777-42010aa00008   1Gi        RWO            standard       1h\\npersistentvolumeclaim/data-mehdb-1   Bound    pvc-be0d2686-4f7e-11e9-9777-42010aa00008   1Gi        RWO            standard       1h\\n\\nNAME                 TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)    AGE   SELECTOR\\nservice/kubernetes   ClusterIP   10.15.240.1   <none>        443/TCP    2d    <none>\\nservice/mehdb        ClusterIP   None          <none>        9876/TCP   1h    app=mehdb\\n\\n# Explicity delete the persistentvolumeclaims\\n$ for i in 0 1; do kubectl delete persistentvolumeclaims data-mehdb-$i; done\\npersistentvolumeclaim \\\"data-mehdb-0\\\" deleted\\npersistentvolumeclaim \\\"data-mehdb-1\\\" deleted\\n\\n# And the service as well\\n$ kubectl delete service mehdb\\nservice \\\"mehdb\\\" deleted\\n\")), mdx(\"p\", null, \"This exercise wasn't very successful though. :-/\"), mdx(\"p\", null, \"[\", mdx(\"sub\", null, mdx(\"sup\", null, mdx(\"a\", {\n    href: \"#top-contents\"\n  }, \"GO TO TOP\"))), \"]\"), mdx(\"h3\", null, \"Init Containers \", mdx(\"a\", {\n    id: \"init-containers\"\n  })), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"It\\u2019s sometimes necessary to prepare a container running in a pod. For example, you might want to wait for a service being available, want to configure things at runtime, or init some data in a database. In all of these cases, init containers are useful. Note that Kubernetes will execute all init containers (and they must all exit successfully) before the main container(s) are executed.\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2,6,14}\",\n    \"{2,6,14}\": true\n  }, \"# Create a deployment consisting of an init container that writes a message into a file at /ic/this and the main (long-running) container reading out this file:\\n$ kubectl apply -f init-containers/deploy.yaml\\ndeployment.apps/ic-deploy created\\n\\n# List the deployment and the pod\\n$ kubectl get deploy,po -o wide\\nNAME                              DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES     SELECTOR\\ndeployment.extensions/ic-deploy   1         1         1            1           29s   main         centos:7   app=ic\\n\\nNAME                            READY   STATUS    RESTARTS   AGE   IP           NODE                                            NOMINATED NODE\\npod/ic-deploy-bf75cbf87-z8nh5   1/1     Running   0          30s   10.12.1.14   gke-k8s-by-example-default-pool-635ddecf-1xsh   <none>\\n\\n# Check the pod logs\\n$ kubectl logs ic-deploy-bf75cbf87-z8nh5 -f\\nINIT_DONE\\nINIT_DONE\\nINIT_DONE\\nINIT_DONE\\nINIT_DONE\\n^C\\n\")), mdx(\"p\", null, \"Clean up time!\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2,6}\",\n    \"{2,6}\": true\n  }, \"# Delete the deployment\\n$ kubectl delete deployments --all\\ndeployment.extensions \\\"ic-deploy\\\" deleted\\n\\n# And the pods are terminating, it can take some time\\n$ kubectl get deploy,po -o wide\\nNAME                            READY   STATUS        RESTARTS   AGE   IP           NODE                                            NOMINATED NODE\\npod/ic-deploy-bf75cbf87-z8nh5   0/1     Terminating   0          7m    10.12.1.14   gke-k8s-by-example-default-pool-635ddecf-1xsh   <none>\\n\")), mdx(\"p\", null, \"Time to move on though!\"), mdx(\"p\", null, \"[\", mdx(\"sub\", null, mdx(\"sup\", null, mdx(\"a\", {\n    href: \"#top-contents\"\n  }, \"GO TO TOP\"))), \"]\"), mdx(\"h3\", null, \"Nodes \", mdx(\"a\", {\n    id: \"nodes\"\n  })), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"... nodes are the (virtual) machines where your workloads in shape of pods run.\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2,9,13,17,22}\",\n    \"{2,9,13,17,22}\": true\n  }, \"# Let's list all the nodes:\\n$ kubectl get nodes -o wide\\nNAME                                            STATUS   ROLES    AGE   VERSION          INTERNAL-IP   EXTERNAL-IP      OS-IMAGE                             KERNEL-VERSION   CONTAINER-RUNTIME\\ngke-k8s-by-example-default-pool-635ddecf-1xsh   Ready    <none>   3d    v1.11.7-gke.12   10.160.0.29   35.200.209.198   Container-Optimized OS from Google   4.14.91+         docker://17.3.2\\ngke-k8s-by-example-default-pool-635ddecf-30n4   Ready    <none>   3d    v1.11.7-gke.12   10.160.0.30   35.244.18.55     Container-Optimized OS from Google   4.14.91+         docker://17.3.2\\ngke-k8s-by-example-default-pool-635ddecf-ll16   Ready    <none>   3d    v1.11.7-gke.12   10.160.0.28   35.200.217.246   Container-Optimized OS from Google   4.14.91+         docker://17.3.2\\n\\n# Label one of the nodes\\n$ kubectl label nodes gke-k8s-by-example-default-pool-635ddecf-1xsh shouldrun=here\\nnode/gke-k8s-by-example-default-pool-635ddecf-1xsh labeled\\n\\n# Now, create a pod to run on the specific node that we just labelled\\n$ kubectl apply -f nodes/pod.yaml\\npod/onspecificnode created\\n\\n# It's running on gke-k8s-by-example-default-pool-635ddecf-1xsh, which is the one we labelled\\n$ kubectl get po -o wide\\nNAME             READY   STATUS    RESTARTS   AGE   IP           NODE                                            NOMINATED NODE\\nonspecificnode   1/1     Running   0          38s   10.12.1.15   gke-k8s-by-example-default-pool-635ddecf-1xsh   <none>\\n\\n# You can learn more about node using describe (portion of the entire dump)\\n$ kubectl describe nodes gke-k8s-by-example-default-pool-635ddecf-1xsh\\n.\\n.\\n.\\nAddresses:\\n  InternalIP:  10.160.0.29\\n  ExternalIP:  35.200.209.198\\n  Hostname:    gke-k8s-by-example-default-pool-635ddecf-1xsh\\nCapacity:\\n cpu:                1\\n ephemeral-storage:  98868448Ki\\n hugepages-2Mi:      0\\n memory:             3787656Ki\\n pods:               110\\nAllocatable:\\n cpu:                940m\\n ephemeral-storage:  47093746742\\n hugepages-2Mi:      0\\n memory:             2702216Ki\\n pods:               110\\nSystem Info:\\n Kernel Version:             4.14.91+\\n OS Image:                   Container-Optimized OS from Google\\n Operating System:           linux\\n Architecture:               amd64\\n Container Runtime Version:  docker://17.3.2\\n Kubelet Version:            v1.11.7-gke.12\\n Kube-Proxy Version:         v1.11.7-gke.12\\nPodCIDR:                     10.12.1.0/24\\n\\n.\\n.\\n.\\n\")), mdx(\"p\", null, \"[\", mdx(\"sub\", null, mdx(\"sup\", null, mdx(\"a\", {\n    href: \"#top-contents\"\n  }, \"GO TO TOP\"))), \"]\"), mdx(\"h3\", null, \"API Server access \", mdx(\"a\", {\n    id: \"api-server-access\"\n  })), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"Sometimes it\\u2019s useful or necessary to directly \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://kubernetes.io/docs/tasks/access-kubernetes-api/http-proxy-access-api/\"\n  }, \"access the Kubernetes API server\"), \", for exploratory or testing purposes.\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2,6}\",\n    \"{2,6}\": true\n  }, \"# In one terminal, proxy the API to the local environment\\n$ kubectl proxy --port=8080\\nStarting to serve on 127.0.0.1:8080\\n\\n# In another terminal, access the API\\n$ curl http://localhost:8080/api/v1\\n{\\n  \\\"kind\\\": \\\"APIResourceList\\\",\\n  \\\"groupVersion\\\": \\\"v1\\\",\\n  \\\"resources\\\": [\\n    {\\n      \\\"name\\\": \\\"bindings\\\",\\n      \\\"singularName\\\": \\\"\\\",\\n      \\\"namespaced\\\": true,\\n      \\\"kind\\\": \\\"Binding\\\",\\n      \\\"verbs\\\": [\\n        \\\"create\\\"\\n      ]\\n    },\\n    .\\n    .\\n    .\\n    .\\n    {\\n      \\\"name\\\": \\\"services/status\\\",\\n      \\\"singularName\\\": \\\"\\\",\\n      \\\"namespaced\\\": true,\\n      \\\"kind\\\": \\\"Service\\\",\\n      \\\"verbs\\\": [\\n        \\\"get\\\",\\n        \\\"patch\\\",\\n        \\\"update\\\"\\n      ]\\n    }\\n  ]\\n}\\n\")), mdx(\"p\", null, \"Another method:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-sh\",\n    \"metastring\": \"{2,5,20}\",\n    \"{2,5,20}\": true\n  }, \"# Use kubectl directly\\n$ kubectl get --raw=/api/v1\\n\\n# Check supported API versions\\n$ kubectl api-versions\\n.\\n.\\napps/v1\\napps/v1beta1\\napps/v1beta2\\n.\\n.\\nbatch/v1\\nbatch/v1beta1\\n.\\n.\\nv1\\n\\n# And resources (I am showing only a few)\\n$ kubectl api-resources\\nNAME                              SHORTNAMES   APIGROUP                       NAMESPACED   KIND\\nconfigmaps                        cm                                          true         ConfigMap\\nendpoints                         ep                                          true         Endpoints\\nevents                            ev                                          true         Event\\nnamespaces                        ns                                          false        Namespace\\nnodes                             no                                          false        Node\\npersistentvolumeclaims            pvc                                         true         PersistentVolumeClaim\\npersistentvolumes                 pv                                          false        PersistentVolume\\npods                              po                                          true         Pod\\nreplicationcontrollers            rc                                          true         ReplicationController\\nsecrets                                                                       true         Secret\\nserviceaccounts                   sa                                          true         ServiceAccount\\nservices                          svc                                         true         Service\\ndaemonsets                        ds           apps                           true         DaemonSet\\ndeployments                       deploy       apps                           true         Deployment\\nreplicasets                       rs           apps                           true         ReplicaSet\\nstatefulsets                      sts          apps                           true         StatefulSet\\ncronjobs                          cj           batch                          true         CronJob\\njobs                                           batch                          true         Job\\nstorageclasses                    sc           storage.k8s.io                 false        StorageClass\\n\")), mdx(\"p\", null, \"That's the end!\"), mdx(\"p\", null, \"[\", mdx(\"sub\", null, mdx(\"sup\", null, mdx(\"a\", {\n    href: \"#top-contents\"\n  }, \"GO TO TOP\"))), \"]\"));\n}\n;\nMDXContent.isMDXComponent = true;","excerpt":"Note : This is a journal of my learnings as I walk through the entire  Kubernetes By Example  exercises on  Google Kubernetes Engine . I had","timeToRead":8,"banner":null}},"pageContext":{"slug":"/kubernetes-by-example-gke","formatString":"DD.MM.YYYY"}},"staticQueryHashes":["3090400250","3090400250","318001574"]}